{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import no_grad\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn import (\n",
    "    Module,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    Dropout2d,\n",
    "    CrossEntropyLoss\n",
    ")\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torchmetrics\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 160\n",
      "Number of test samples: 40\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "batch_size = 16\n",
    "\n",
    "# Train DataLoader\n",
    "data_root = \"./music/\"\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    #transforms.Resize((400, 1000)), \n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "custom_dataset = datasets.ImageFolder(root=data_root, transform=data_transform)\n",
    "train_dataset = custom_dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"Number of training samples:\", len(train_dataset))\n",
    "\n",
    "# Test DataLoader\n",
    "data_root = \"./music_test/\" \n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    #transforms.Resize((400, 1000)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "custom_dataset = datasets.ImageFolder(root=data_root, transform=data_transform)\n",
    "test_dataset = custom_dataset\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)\n",
    "\n",
    "print(\"Number of test samples:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(3, 2, kernel_size=5)\n",
    "        self.conv2 = Conv2d(2, 16, kernel_size=5)\n",
    "        self.conv3 = Conv2d(16, 64, kernel_size=5)\n",
    "        self.dropout = Dropout2d()\n",
    "        self.fc1 = Linear(102400, 64)\n",
    "        self.fc2 = Linear(64, 32)\n",
    "        self.fc3 = Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))      \n",
    "        x= self.fc3(x)\n",
    "        return torch.cat((x, 1 - x), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8728, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7493, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7483, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8082, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8667, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6851, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8626, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7991, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8561, grad_fn=<NllLossBackward0>)\n",
      "Training [2%]\tLoss: 0.8060\n",
      "tensor(0.8525, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9063, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7373, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6767, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7298, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0471, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8235, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8681, grad_fn=<NllLossBackward0>)\n",
      "Training [4%]\tLoss: 0.7834\n",
      "tensor(0.8164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7584, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8415, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7900, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7054, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7092, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7004, grad_fn=<NllLossBackward0>)\n",
      "Training [6%]\tLoss: 0.7560\n",
      "tensor(0.7042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7297, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8411, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6707, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7850, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7238, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6557, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7390, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6890, grad_fn=<NllLossBackward0>)\n",
      "Training [8%]\tLoss: 0.7261\n",
      "tensor(0.6375, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7423, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6835, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6890, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6900, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7203, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6862, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7829, grad_fn=<NllLossBackward0>)\n",
      "Training [10%]\tLoss: 0.7035\n",
      "tensor(0.7113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6970, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6875, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6759, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6974, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6602, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6848, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7254, grad_fn=<NllLossBackward0>)\n",
      "Training [12%]\tLoss: 0.6944\n",
      "tensor(0.6785, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6818, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6978, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7708, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6703, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6787, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6645, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7064, grad_fn=<NllLossBackward0>)\n",
      "Training [14%]\tLoss: 0.6988\n",
      "tensor(0.6977, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6789, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6986, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6944, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7012, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7129, grad_fn=<NllLossBackward0>)\n",
      "Training [16%]\tLoss: 0.6947\n",
      "tensor(0.6983, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7323, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7028, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6527, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6950, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6951, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6849, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6876, grad_fn=<NllLossBackward0>)\n",
      "Training [18%]\tLoss: 0.6967\n",
      "tensor(0.7118, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6882, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6504, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6322, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6750, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6980, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7135, grad_fn=<NllLossBackward0>)\n",
      "Training [20%]\tLoss: 0.6898\n",
      "tensor(0.6979, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6726, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7367, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6876, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6929, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6869, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6673, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6977, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6783, grad_fn=<NllLossBackward0>)\n",
      "Training [22%]\tLoss: 0.6938\n",
      "tensor(0.6737, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6836, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6913, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7075, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6635, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6612, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6993, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7045, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6684, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6734, grad_fn=<NllLossBackward0>)\n",
      "Training [24%]\tLoss: 0.6826\n",
      "tensor(0.6830, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6908, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6691, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6997, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6875, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6989, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6953, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6590, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7066, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6854, grad_fn=<NllLossBackward0>)\n",
      "Training [26%]\tLoss: 0.6875\n",
      "tensor(0.6955, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6519, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6781, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7017, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6864, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6938, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6609, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6655, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6857, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6782, grad_fn=<NllLossBackward0>)\n",
      "Training [28%]\tLoss: 0.6798\n",
      "tensor(0.6932, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6508, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6865, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6635, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6867, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6791, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6473, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6917, grad_fn=<NllLossBackward0>)\n",
      "Training [30%]\tLoss: 0.6730\n",
      "tensor(0.6765, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6678, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6600, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6890, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6624, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6773, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6882, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6509, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6729, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6722, grad_fn=<NllLossBackward0>)\n",
      "Training [32%]\tLoss: 0.6717\n",
      "tensor(0.6809, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6392, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6472, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6766, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6697, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6319, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6719, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6954, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6970, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6798, grad_fn=<NllLossBackward0>)\n",
      "Training [34%]\tLoss: 0.6690\n",
      "tensor(0.6645, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6874, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6792, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6797, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6751, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6581, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6353, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6759, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6653, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6637, grad_fn=<NllLossBackward0>)\n",
      "Training [36%]\tLoss: 0.6684\n",
      "tensor(0.6417, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6584, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6855, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6526, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6424, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6695, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6317, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6687, grad_fn=<NllLossBackward0>)\n",
      "Training [38%]\tLoss: 0.6553\n",
      "tensor(0.6606, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6288, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6558, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6579, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6369, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6850, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6381, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6336, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6513, grad_fn=<NllLossBackward0>)\n",
      "Training [40%]\tLoss: 0.6471\n",
      "tensor(0.6384, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6381, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6442, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6361, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5740, grad_fn=<NllLossBackward0>)\n",
      "Training [42%]\tLoss: 0.6250\n",
      "tensor(0.6430, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6855, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6274, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6243, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6275, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6250, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6158, grad_fn=<NllLossBackward0>)\n",
      "Training [44%]\tLoss: 0.6303\n",
      "tensor(0.6276, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5491, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6417, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5737, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5858, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7381, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6881, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5923, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5750, grad_fn=<NllLossBackward0>)\n",
      "Training [46%]\tLoss: 0.6172\n",
      "tensor(0.5932, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5806, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5846, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5728, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5430, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5862, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6020, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7315, grad_fn=<NllLossBackward0>)\n",
      "Training [48%]\tLoss: 0.5910\n",
      "tensor(0.5371, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5199, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6830, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6605, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5283, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4797, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4977, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5770, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7091, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6502, grad_fn=<NllLossBackward0>)\n",
      "Training [50%]\tLoss: 0.5842\n",
      "tensor(0.5019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5371, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4687, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5829, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4693, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5651, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4219, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5920, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4375, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5407, grad_fn=<NllLossBackward0>)\n",
      "Training [52%]\tLoss: 0.5117\n",
      "tensor(0.5481, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6089, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6057, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4922, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5556, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4581, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4372, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4218, grad_fn=<NllLossBackward0>)\n",
      "Training [54%]\tLoss: 0.4852\n",
      "tensor(0.3161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5378, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3739, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3656, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4059, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5320, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5828, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4357, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4065, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4749, grad_fn=<NllLossBackward0>)\n",
      "Training [56%]\tLoss: 0.4431\n",
      "tensor(0.5696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5103, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4786, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5610, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3588, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2934, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3777, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4501, grad_fn=<NllLossBackward0>)\n",
      "Training [58%]\tLoss: 0.4522\n",
      "tensor(0.4842, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5738, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4117, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3563, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2537, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2430, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3647, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3961, grad_fn=<NllLossBackward0>)\n",
      "Training [60%]\tLoss: 0.3734\n",
      "tensor(0.3961, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2611, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3569, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2735, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2942, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3352, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2907, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3999, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1935, grad_fn=<NllLossBackward0>)\n",
      "Training [62%]\tLoss: 0.3203\n",
      "tensor(0.3210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1971, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3691, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1550, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3395, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3628, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2021, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2955, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7667, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2411, grad_fn=<NllLossBackward0>)\n",
      "Training [64%]\tLoss: 0.3250\n",
      "tensor(0.2872, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2042, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1324, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3846, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2478, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3773, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1517, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2353, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1638, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4479, grad_fn=<NllLossBackward0>)\n",
      "Training [66%]\tLoss: 0.2632\n",
      "tensor(0.2983, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0524, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3675, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2854, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2640, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2275, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6515, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1800, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1048, grad_fn=<NllLossBackward0>)\n",
      "Training [68%]\tLoss: 0.2544\n",
      "tensor(0.3290, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1366, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1062, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0811, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0997, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1390, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4450, grad_fn=<NllLossBackward0>)\n",
      "Training [70%]\tLoss: 0.2176\n",
      "tensor(0.5459, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1489, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4120, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1580, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1833, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0552, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0827, grad_fn=<NllLossBackward0>)\n",
      "Training [72%]\tLoss: 0.1967\n",
      "tensor(0.1177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1750, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1863, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1724, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1974, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0881, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0906, grad_fn=<NllLossBackward0>)\n",
      "Training [74%]\tLoss: 0.1776\n",
      "tensor(0.0504, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0982, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1116, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4701, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1701, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0761, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0733, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0623, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1329, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2343, grad_fn=<NllLossBackward0>)\n",
      "Training [76%]\tLoss: 0.1479\n",
      "tensor(0.0833, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0571, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2420, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1405, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1416, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0611, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1384, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0522, grad_fn=<NllLossBackward0>)\n",
      "Training [78%]\tLoss: 0.1242\n",
      "tensor(0.1284, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0536, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0786, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0710, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2970, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0445, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1499, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2197, grad_fn=<NllLossBackward0>)\n",
      "Training [80%]\tLoss: 0.1200\n",
      "tensor(0.3757, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3388, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1651, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0503, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0362, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0674, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2414, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0862, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1380, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1988, grad_fn=<NllLossBackward0>)\n",
      "Training [82%]\tLoss: 0.1698\n",
      "tensor(0.1865, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1349, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0864, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2730, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0579, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0728, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0700, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0661, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1668, grad_fn=<NllLossBackward0>)\n",
      "Training [84%]\tLoss: 0.1320\n",
      "tensor(0.0865, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1924, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0474, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0473, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3272, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1974, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0151, grad_fn=<NllLossBackward0>)\n",
      "Training [86%]\tLoss: 0.1149\n",
      "tensor(0.3954, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0616, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1491, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0735, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0243, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0466, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0874, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0512, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1311, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4273, grad_fn=<NllLossBackward0>)\n",
      "Training [88%]\tLoss: 0.1448\n",
      "tensor(0.0445, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3835, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0732, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0761, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0573, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0524, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1856, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0613, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2844, grad_fn=<NllLossBackward0>)\n",
      "Training [90%]\tLoss: 0.1335\n",
      "tensor(0.0464, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0607, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0542, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4043, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0455, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0614, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3574, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0454, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0576, grad_fn=<NllLossBackward0>)\n",
      "Training [92%]\tLoss: 0.1167\n",
      "tensor(0.2267, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1492, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1014, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0852, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1425, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0876, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0370, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0454, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1745, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1299, grad_fn=<NllLossBackward0>)\n",
      "Training [94%]\tLoss: 0.1179\n",
      "tensor(0.3776, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0381, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1016, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0413, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0826, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1298, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0509, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1428, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0689, grad_fn=<NllLossBackward0>)\n",
      "Training [96%]\tLoss: 0.1153\n",
      "tensor(0.0591, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1471, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1074, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3441, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0418, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2541, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0933, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0322, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0653, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1175, grad_fn=<NllLossBackward0>)\n",
      "Training [98%]\tLoss: 0.1262\n",
      "tensor(0.0204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0301, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0379, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0480, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4849, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0419, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0737, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2504, grad_fn=<NllLossBackward0>)\n",
      "Training [100%]\tLoss: 0.1059\n"
     ]
    }
   ],
   "source": [
    "model = CNN() # Model\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # Optimizer \n",
    "loss_func = CrossEntropyLoss() # Loss Functions\n",
    "epochs = 50  # Set number of epochs\n",
    "loss_list = []  # Store loss history\n",
    "\n",
    "model.train()  # Set model to training mode\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad(set_to_none=True)  # Initialize gradient\n",
    "        output = model(data)  # Forward pass\n",
    "        loss = loss_func(output, target)  # Calculate loss\n",
    "        print(loss)\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize weights\n",
    "        total_loss.append(loss.item())  # Store loss\n",
    "    loss_list.append(sum(total_loss) / len(total_loss))\n",
    "    print(\"Training [{:.0f}%]\\tLoss: {:.4f}\".format(100.0 * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title(\"Hybrid NN Training Convergence\")\n",
    "plt.xlabel(\"Training Iterations\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'models/music_cnn_classical.pt'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "PATH = 'models/music_cnn_classical.pt'\n",
    "model = CNN()\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 2, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(2, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(16, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (dropout): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=102400, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.classification import Accuracy, ConfusionMatrix, BinaryF1Score, BinaryPrecision, BinaryRecall, BinaryHingeLoss\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875\n",
      "Cross-Entropy Loss: 0.01767023093998432\n",
      "Confusion Matrix:\n",
      "[[15, 5], [0, 20]]\n",
      "F1 Score: 0.8888888955116272\n",
      "Binary Precision: 0.800000011920929\n",
      "Binary Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        y_true.extend(labels.tolist())\n",
    "        y_pred_probs.extend(probabilities.tolist())\n",
    "\n",
    "y_pred_probs = torch.tensor(y_pred_probs)\n",
    "y_pred = torch.argmax(y_pred_probs, dim=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = Accuracy(task=\"binary\")(y_pred, torch.tensor(y_true))\n",
    "print(\"Accuracy:\", accuracy.item())\n",
    "\n",
    "# Calculate cross-entropy loss\n",
    "loss_func = CrossEntropyLoss()\n",
    "CELoss = loss_func(outputs, labels)\n",
    "print(\"Cross-Entropy Loss:\", CELoss.item())\n",
    "\n",
    "# Calculate confusion matrix\n",
    "confmat = ConfusionMatrix(task=\"binary\", num_classes=2)\n",
    "confmat_result = confmat(y_pred, torch.tensor(y_true))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confmat_result.tolist())\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = BinaryF1Score()\n",
    "f1_result = f1(y_pred, torch.tensor(y_true))\n",
    "print(\"F1 Score:\", f1_result.item())\n",
    "\n",
    "# Calculate Binary Precision\n",
    "precision = BinaryPrecision()\n",
    "precision_result = precision(y_pred, torch.tensor(y_true))\n",
    "print(\"Binary Precision:\", precision_result.item())\n",
    "\n",
    "# Calculate Binary Recall\n",
    "recall = BinaryRecall()\n",
    "recall_result = recall(y_pred, torch.tensor(y_true))\n",
    "print(\"Binary Recall:\", recall_result.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.987500011920929\n",
      "Cross-Entropy Loss: 0.027862343937158585\n",
      "Confusion Matrix:\n",
      "[[80, 0], [2, 78]]\n",
      "F1 Score: 0.9873417615890503\n",
      "Binary Precision: 1.0\n",
      "Binary Recall: 0.9750000238418579\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        outputs = model(images)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        y_true.extend(labels.tolist())\n",
    "        y_pred_probs.extend(probabilities.tolist())\n",
    "\n",
    "y_pred_probs = torch.tensor(y_pred_probs)\n",
    "y_pred = torch.argmax(y_pred_probs, dim=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = Accuracy(task=\"binary\")(y_pred, torch.tensor(y_true))\n",
    "print(\"Accuracy:\", accuracy.item())\n",
    "\n",
    "# Calculate cross-entropy loss\n",
    "loss_func = CrossEntropyLoss()\n",
    "CELoss = loss_func(outputs, labels)\n",
    "print(\"Cross-Entropy Loss:\", CELoss.item())\n",
    "\n",
    "# Calculate confusion matrix\n",
    "confmat = ConfusionMatrix(task=\"binary\", num_classes=2)\n",
    "confmat_result = confmat(y_pred, torch.tensor(y_true))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confmat_result.tolist())\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1 = BinaryF1Score()\n",
    "f1_result = f1(y_pred, torch.tensor(y_true))\n",
    "print(\"F1 Score:\", f1_result.item())\n",
    "\n",
    "# Calculate Binary Precision\n",
    "precision = BinaryPrecision()\n",
    "precision_result = precision(y_pred, torch.tensor(y_true))\n",
    "print(\"Binary Precision:\", precision_result.item())\n",
    "\n",
    "# Calculate Binary Recall\n",
    "recall = BinaryRecall()\n",
    "recall_result = recall(y_pred, torch.tensor(y_true))\n",
    "print(\"Binary Recall:\", recall_result.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
