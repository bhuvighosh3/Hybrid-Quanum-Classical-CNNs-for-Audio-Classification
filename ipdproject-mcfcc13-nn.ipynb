{"cells":[{"cell_type":"code","execution_count":17,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-11T06:39:18.643709Z","iopub.status.busy":"2024-03-11T06:39:18.643231Z","iopub.status.idle":"2024-03-11T06:39:37.117875Z","shell.execute_reply":"2024-03-11T06:39:37.116136Z","shell.execute_reply.started":"2024-03-11T06:39:18.643669Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","from sklearn.metrics import accuracy_score, classification_report\n","from keras.models import Sequential\n","from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n","from sklearn.model_selection import train_test_split\n","import numpy as np"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["df_x = pd.read_csv(\"pre_processed_data/df_x_n_mfcc13.csv\") "]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["df_y = pd.read_csv(\"pre_processed_data/df_y_n_mfcc13.csv\")"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["x = np.array(df_x).reshape(-1, 13, 1)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Yash Thakar\\PROGRAMMING\\Quantum\\env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]}],"source":["label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(df_y)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[  0   1   2   3   4]\n"," [174 229 210 222 138]]\n"]}],"source":["unique_elements, counts_elements = np.unique(y_encoded, return_counts=True)\n","print(np.asarray((unique_elements, counts_elements)))"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, \n","                                                    test_size=0.2, random_state = 42)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Yash Thakar\\PROGRAMMING\\Quantum\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.2120 - loss: 10.5832 - val_accuracy: 0.4256 - val_loss: 1.5837\n","Epoch 2/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2440 - loss: 3.7604 - val_accuracy: 0.3385 - val_loss: 1.6050\n","Epoch 3/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2381 - loss: 2.6084 - val_accuracy: 0.3949 - val_loss: 1.4731\n","Epoch 4/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2587 - loss: 2.0971 - val_accuracy: 0.3897 - val_loss: 1.4665\n","Epoch 5/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3362 - loss: 1.8306 - val_accuracy: 0.4513 - val_loss: 1.4073\n","Epoch 6/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2864 - loss: 1.8103 - val_accuracy: 0.4256 - val_loss: 1.3716\n","Epoch 7/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3122 - loss: 1.7210 - val_accuracy: 0.4974 - val_loss: 1.3417\n","Epoch 8/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3063 - loss: 1.6278 - val_accuracy: 0.4923 - val_loss: 1.3401\n","Epoch 9/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3220 - loss: 1.5816 - val_accuracy: 0.4308 - val_loss: 1.3051\n","Epoch 10/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3376 - loss: 1.5299 - val_accuracy: 0.4718 - val_loss: 1.3166\n","Epoch 11/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3327 - loss: 1.5283 - val_accuracy: 0.4974 - val_loss: 1.2931\n","Epoch 12/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3561 - loss: 1.4534 - val_accuracy: 0.4872 - val_loss: 1.2673\n","Epoch 13/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3959 - loss: 1.3894 - val_accuracy: 0.4769 - val_loss: 1.2631\n","Epoch 14/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3827 - loss: 1.4234 - val_accuracy: 0.5231 - val_loss: 1.2401\n","Epoch 15/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3597 - loss: 1.4233 - val_accuracy: 0.5282 - val_loss: 1.2120\n","Epoch 16/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3929 - loss: 1.4325 - val_accuracy: 0.5744 - val_loss: 1.1909\n","Epoch 17/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4103 - loss: 1.3426 - val_accuracy: 0.5333 - val_loss: 1.1984\n","Epoch 18/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3828 - loss: 1.3541 - val_accuracy: 0.5846 - val_loss: 1.2291\n","Epoch 19/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.3850 - loss: 1.3613 - val_accuracy: 0.5487 - val_loss: 1.1589\n","Epoch 20/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4264 - loss: 1.3421 - val_accuracy: 0.5744 - val_loss: 1.1899\n","Epoch 21/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4453 - loss: 1.3085 - val_accuracy: 0.5538 - val_loss: 1.1634\n","Epoch 22/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4569 - loss: 1.3070 - val_accuracy: 0.5795 - val_loss: 1.1244\n","Epoch 23/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4228 - loss: 1.3226 - val_accuracy: 0.6000 - val_loss: 1.1306\n","Epoch 24/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4704 - loss: 1.2649 - val_accuracy: 0.5744 - val_loss: 1.1437\n","Epoch 25/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4616 - loss: 1.2611 - val_accuracy: 0.5795 - val_loss: 1.1439\n","Epoch 26/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4343 - loss: 1.2459 - val_accuracy: 0.5641 - val_loss: 1.1157\n","Epoch 27/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4270 - loss: 1.2781 - val_accuracy: 0.5641 - val_loss: 1.0887\n","Epoch 28/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4877 - loss: 1.2207 - val_accuracy: 0.5641 - val_loss: 1.1157\n","Epoch 29/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4518 - loss: 1.2451 - val_accuracy: 0.6051 - val_loss: 1.0772\n","Epoch 30/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4611 - loss: 1.2101 - val_accuracy: 0.5590 - val_loss: 1.0812\n","Epoch 31/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4590 - loss: 1.2299 - val_accuracy: 0.5538 - val_loss: 1.1006\n","Epoch 32/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4644 - loss: 1.1916 - val_accuracy: 0.5949 - val_loss: 1.0928\n","Epoch 33/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5207 - loss: 1.1713 - val_accuracy: 0.5795 - val_loss: 1.0549\n","Epoch 34/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4694 - loss: 1.2197 - val_accuracy: 0.5744 - val_loss: 1.0769\n","Epoch 35/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4640 - loss: 1.2358 - val_accuracy: 0.5641 - val_loss: 1.0596\n","Epoch 36/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4709 - loss: 1.1533 - val_accuracy: 0.5744 - val_loss: 1.0606\n","Epoch 37/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4854 - loss: 1.1932 - val_accuracy: 0.6051 - val_loss: 1.0312\n","Epoch 38/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4890 - loss: 1.2213 - val_accuracy: 0.5846 - val_loss: 1.0401\n","Epoch 39/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4569 - loss: 1.2366 - val_accuracy: 0.5795 - val_loss: 1.0616\n","Epoch 40/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5121 - loss: 1.1810 - val_accuracy: 0.5590 - val_loss: 1.0558\n","Epoch 41/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5072 - loss: 1.1374 - val_accuracy: 0.5846 - val_loss: 1.0456\n","Epoch 42/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5015 - loss: 1.1866 - val_accuracy: 0.5487 - val_loss: 1.0389\n","Epoch 43/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4661 - loss: 1.1876 - val_accuracy: 0.5744 - val_loss: 1.0447\n","Epoch 44/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5032 - loss: 1.1423 - val_accuracy: 0.5744 - val_loss: 1.0263\n","Epoch 45/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5209 - loss: 1.1910 - val_accuracy: 0.5641 - val_loss: 1.0426\n","Epoch 46/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4942 - loss: 1.1683 - val_accuracy: 0.5795 - val_loss: 1.0193\n","Epoch 47/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4783 - loss: 1.2196 - val_accuracy: 0.5333 - val_loss: 1.0596\n","Epoch 48/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5081 - loss: 1.1293 - val_accuracy: 0.5590 - val_loss: 1.0207\n","Epoch 49/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5016 - loss: 1.1143 - val_accuracy: 0.5744 - val_loss: 1.0221\n","Epoch 50/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5144 - loss: 1.1031 - val_accuracy: 0.5897 - val_loss: 0.9998\n","Epoch 51/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5326 - loss: 1.0774 - val_accuracy: 0.5744 - val_loss: 1.0132\n","Epoch 52/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5125 - loss: 1.1287 - val_accuracy: 0.5795 - val_loss: 1.0354\n","Epoch 53/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5637 - loss: 1.1014 - val_accuracy: 0.5795 - val_loss: 1.0115\n","Epoch 54/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4926 - loss: 1.1143 - val_accuracy: 0.5897 - val_loss: 1.0063\n","Epoch 55/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5350 - loss: 1.1244 - val_accuracy: 0.5949 - val_loss: 0.9980\n","Epoch 56/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5192 - loss: 1.1142 - val_accuracy: 0.5744 - val_loss: 1.0033\n","Epoch 57/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5186 - loss: 1.1385 - val_accuracy: 0.5538 - val_loss: 0.9809\n","Epoch 58/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5274 - loss: 1.0642 - val_accuracy: 0.5949 - val_loss: 0.9775\n","Epoch 59/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5384 - loss: 1.0876 - val_accuracy: 0.5590 - val_loss: 1.0393\n","Epoch 60/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4924 - loss: 1.1468 - val_accuracy: 0.5641 - val_loss: 0.9861\n","Epoch 61/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5339 - loss: 1.0939 - val_accuracy: 0.6051 - val_loss: 0.9956\n","Epoch 62/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5173 - loss: 1.1240 - val_accuracy: 0.5795 - val_loss: 0.9585\n","Epoch 63/100\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5494 - loss: 1.0716 - val_accuracy: 0.5795 - val_loss: 0.9818\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x200885b5010>"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# Create the model\n","model = Sequential()\n","\n","# Add convolutional layers\n","model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(13, 1)))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Conv1D(64, kernel_size=3, activation='relu'))\n","model.add(MaxPooling1D(pool_size=2))\n","\n","# Flatten the output of the convolutional layers\n","model.add(Flatten())\n","\n","# Add dense layers\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.3))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dropout(0.3))\n","model.add(Dense(5, activation='softmax')) \n","\n","\n","# Compile the model\n","optimiser = tf.keras.optimizers.Adam(learning_rate = 0.0002)\n","cb = [EarlyStopping(patience=10,monitor='accuracy',mode='max',restore_best_weights=True)]\n","model.compile(optimizer=optimiser, loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","# Train the model\n","model.fit(x_train, y_train, epochs=100, batch_size=16, validation_data=(x_test, y_test), callbacks = cb)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"]}],"source":["y_pred = model.predict(x_test)\n","y_pred_classes = y_pred.argmax(axis=1)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["array([[1.12535238e-01, 7.99975872e-01, 1.11328205e-02, 4.09071818e-02,\n","        3.54488604e-02],\n","       [1.98186740e-01, 1.33148670e-01, 2.48404965e-01, 2.26746097e-01,\n","        1.93513423e-01],\n","       [1.36377513e-01, 5.45880273e-02, 3.02173585e-01, 2.93308437e-01,\n","        2.13552386e-01],\n","       [1.85458601e-01, 1.40620559e-01, 2.63856739e-01, 2.07607299e-01,\n","        2.02456892e-01],\n","       [1.36080503e-01, 2.26698115e-01, 1.38093501e-01, 3.65159452e-01,\n","        1.33968413e-01],\n","       [1.73589483e-01, 7.45860487e-02, 2.12514788e-01, 3.73554051e-01,\n","        1.65755644e-01],\n","       [1.72483206e-01, 1.18116707e-01, 3.05036604e-01, 1.85582027e-01,\n","        2.18781471e-01],\n","       [5.61063825e-06, 9.99994159e-01, 1.24570898e-09, 1.45297264e-07,\n","        1.53976146e-07],\n","       [1.09642394e-01, 2.22235486e-01, 1.21633805e-01, 4.16843981e-01,\n","        1.29644364e-01],\n","       [3.40161860e-01, 2.28610456e-01, 1.35323554e-01, 1.49289370e-01,\n","        1.46614701e-01],\n","       [2.15665489e-01, 7.94889107e-02, 3.34043831e-01, 1.67995960e-01,\n","        2.02805832e-01],\n","       [2.05896854e-01, 3.09281386e-02, 3.19528848e-01, 2.79568821e-01,\n","        1.64077312e-01],\n","       [2.45668381e-01, 3.66389692e-01, 1.12828493e-01, 1.12818085e-01,\n","        1.62295282e-01],\n","       [1.81335121e-01, 1.28103584e-01, 2.85248250e-01, 1.95767120e-01,\n","        2.09545940e-01],\n","       [7.57214411e-06, 9.99991775e-01, 4.18166080e-09, 2.62325301e-07,\n","        3.98078441e-07],\n","       [6.01061344e-01, 1.70652792e-01, 6.81409761e-02, 8.72403383e-02,\n","        7.29045346e-02],\n","       [1.21312924e-05, 9.99984622e-01, 2.98164622e-08, 1.76623507e-06,\n","        1.45908189e-06],\n","       [2.15459675e-01, 3.93326692e-02, 3.24621290e-01, 2.45193765e-01,\n","        1.75392658e-01],\n","       [2.58298755e-01, 5.69990603e-03, 4.40325707e-01, 5.00416718e-02,\n","        2.45633960e-01],\n","       [2.12262750e-01, 3.58701907e-02, 3.24431330e-01, 2.56081671e-01,\n","        1.71354055e-01],\n","       [7.21028709e-06, 9.99986887e-01, 3.03381071e-08, 4.81937059e-06,\n","        1.09353709e-06],\n","       [1.74872041e-01, 4.44226116e-02, 4.10727650e-01, 1.37461916e-01,\n","        2.32515708e-01],\n","       [2.14428455e-01, 3.76309492e-02, 3.24725300e-01, 2.49720663e-01,\n","        1.73494622e-01],\n","       [2.15338573e-01, 3.87080982e-02, 3.24872047e-01, 2.46400341e-01,\n","        1.74680963e-01],\n","       [1.72043651e-01, 1.12251908e-01, 3.07568967e-01, 1.88083559e-01,\n","        2.20051944e-01],\n","       [2.10759044e-01, 3.49402390e-02, 3.23864669e-01, 2.60676324e-01,\n","        1.69759691e-01],\n","       [1.95501477e-01, 4.36614752e-02, 4.02981043e-01, 1.43770307e-01,\n","        2.14085728e-01],\n","       [1.93738833e-01, 2.48480365e-02, 3.00326794e-01, 3.29031736e-01,\n","        1.52054638e-01],\n","       [1.87754661e-01, 1.28094882e-01, 2.71298707e-01, 2.10619211e-01,\n","        2.02232510e-01],\n","       [2.70066708e-01, 3.47187147e-02, 3.97982210e-01, 1.25413552e-01,\n","        1.71818778e-01],\n","       [1.50315044e-03, 9.92794454e-01, 1.83554032e-04, 4.38751513e-03,\n","        1.13132945e-03],\n","       [1.79268941e-01, 1.13565356e-01, 2.90905833e-01, 2.09057033e-01,\n","        2.07202896e-01],\n","       [1.87039733e-01, 1.27978906e-01, 2.81590849e-01, 2.00204238e-01,\n","        2.03186288e-01],\n","       [1.43887311e-01, 8.18791837e-02, 3.54143590e-01, 1.60151407e-01,\n","        2.59938478e-01],\n","       [2.67736226e-01, 1.52071267e-02, 4.57714617e-01, 8.61903727e-02,\n","        1.73151746e-01],\n","       [1.98439360e-01, 1.34298027e-01, 2.47678176e-01, 2.27534235e-01,\n","        1.92050248e-01],\n","       [2.21291244e-01, 1.04206063e-01, 2.79836774e-01, 1.98896497e-01,\n","        1.95769385e-01],\n","       [8.35236013e-02, 2.11216167e-01, 1.01946399e-01, 5.10894358e-01,\n","        9.24194753e-02],\n","       [1.23565882e-01, 4.81137112e-02, 4.07146871e-01, 1.86195880e-01,\n","        2.34977707e-01],\n","       [3.20432037e-01, 4.04418521e-02, 3.35580945e-01, 1.08270779e-01,\n","        1.95274413e-01],\n","       [1.06207805e-03, 9.93815184e-01, 1.35816896e-04, 4.10373928e-03,\n","        8.83156143e-04],\n","       [2.14456290e-01, 3.76314186e-02, 3.24672222e-01, 2.49763459e-01,\n","        1.73476562e-01],\n","       [1.91051170e-01, 1.33814082e-01, 2.59290785e-01, 2.16758534e-01,\n","        1.99085355e-01],\n","       [1.49972916e-01, 6.14356529e-03, 3.50881696e-01, 9.12200511e-02,\n","        4.01781768e-01],\n","       [2.71065325e-01, 3.48118655e-02, 3.97215337e-01, 1.25284806e-01,\n","        1.71622604e-01],\n","       [1.04303725e-01, 5.10273390e-02, 4.39713418e-01, 1.32600188e-01,\n","        2.72355288e-01],\n","       [1.49335161e-01, 1.63342252e-01, 1.66157171e-01, 3.68044823e-01,\n","        1.53120592e-01],\n","       [6.16503358e-01, 6.11890890e-02, 1.05864257e-01, 1.03721268e-01,\n","        1.12722047e-01],\n","       [5.33423364e-01, 3.24274339e-02, 1.76342472e-01, 9.84312221e-02,\n","        1.59375519e-01],\n","       [5.95018826e-03, 9.91289139e-01, 9.99407712e-05, 1.83092640e-03,\n","        8.29769357e-04],\n","       [1.84206426e-01, 1.22297108e-01, 2.92633832e-01, 1.74828053e-01,\n","        2.26034567e-01],\n","       [1.82608366e-01, 1.14648931e-01, 2.98486114e-01, 2.00182229e-01,\n","        2.04074442e-01],\n","       [1.56384140e-01, 6.13014773e-02, 3.99796635e-01, 1.45158559e-01,\n","        2.37359181e-01],\n","       [1.04644418e-01, 6.43007597e-03, 6.68535411e-01, 8.41208398e-02,\n","        1.36269316e-01],\n","       [2.01905489e-01, 2.87180115e-02, 3.12450886e-01, 2.97837198e-01,\n","        1.59088343e-01],\n","       [1.34486745e-05, 9.99946594e-01, 1.07474428e-07, 3.70074777e-05,\n","        2.86104364e-06],\n","       [2.24841442e-05, 9.99974489e-01, 2.52781600e-08, 1.33224341e-06,\n","        1.71137197e-06],\n","       [9.17159639e-07, 9.99998927e-01, 1.78029994e-10, 1.10083622e-08,\n","        1.19180797e-07],\n","       [1.33457165e-02, 9.11896303e-02, 1.05954381e-02, 8.68443549e-01,\n","        1.64257139e-02],\n","       [4.86368358e-01, 4.23973799e-02, 1.77351266e-01, 1.25825927e-01,\n","        1.68057114e-01],\n","       [1.75662979e-01, 7.67868236e-02, 2.13682324e-01, 3.67280722e-01,\n","        1.66587144e-01],\n","       [1.57917261e-01, 1.12039022e-01, 3.21059555e-01, 1.77004457e-01,\n","        2.31979698e-01],\n","       [1.92725584e-01, 1.05495006e-01, 2.20803007e-01, 3.05451870e-01,\n","        1.75524488e-01],\n","       [1.52030215e-01, 1.28203735e-01, 3.14537972e-01, 1.69872403e-01,\n","        2.35355735e-01],\n","       [1.72367215e-01, 1.75297916e-01, 1.59254074e-01, 3.39130580e-01,\n","        1.53950185e-01],\n","       [1.72105208e-01, 6.62598535e-02, 2.21455216e-01, 3.76575798e-01,\n","        1.63603902e-01],\n","       [2.35726088e-01, 1.73701253e-02, 4.78106618e-01, 9.13779810e-02,\n","        1.77419156e-01],\n","       [1.76017238e-07, 9.99999762e-01, 2.27307721e-11, 8.83414319e-09,\n","        5.81012793e-09],\n","       [8.50168895e-03, 9.88385916e-01, 1.41679673e-04, 1.61088549e-03,\n","        1.35980849e-03],\n","       [1.46858065e-05, 9.99983430e-01, 8.78290685e-09, 3.57621957e-07,\n","        1.48873926e-06],\n","       [1.78483158e-01, 1.31317899e-01, 2.75686800e-01, 2.06473842e-01,\n","        2.08038256e-01],\n","       [1.91362664e-01, 2.54008491e-02, 4.53949034e-01, 1.15536392e-01,\n","        2.13751048e-01],\n","       [1.89218953e-01, 8.35511237e-02, 2.45443836e-01, 3.07263196e-01,\n","        1.74522847e-01],\n","       [1.87535480e-01, 1.09829783e-01, 2.71758944e-01, 2.32649162e-01,\n","        1.98226735e-01],\n","       [1.32444233e-01, 1.00499116e-01, 3.59577507e-01, 1.33480400e-01,\n","        2.73998708e-01],\n","       [1.51296675e-01, 2.22374856e-01, 1.54359117e-01, 3.30562562e-01,\n","        1.41406760e-01],\n","       [1.60915911e-01, 1.72882333e-01, 1.62449956e-01, 3.51276904e-01,\n","        1.52474925e-01],\n","       [3.24636837e-03, 9.95704949e-01, 3.90320965e-05, 3.63139960e-04,\n","        6.46556204e-04],\n","       [1.90049842e-01, 1.30831137e-01, 2.67159969e-01, 2.11504102e-01,\n","        2.00454980e-01],\n","       [1.75411209e-01, 7.93689415e-02, 3.41414422e-01, 1.90196335e-01,\n","        2.13609084e-01],\n","       [1.81854203e-01, 1.72138494e-02, 2.84293652e-01, 3.71556103e-01,\n","        1.45082235e-01],\n","       [1.01671048e-05, 9.99988556e-01, 1.02985966e-08, 5.22213156e-07,\n","        8.04770877e-07],\n","       [1.24821614e-03, 9.98517215e-01, 4.86170575e-06, 1.41000652e-04,\n","        8.86341295e-05],\n","       [1.49818495e-01, 7.30394647e-02, 3.18437308e-01, 2.39412323e-01,\n","        2.19292402e-01],\n","       [1.93387881e-01, 1.73256159e-01, 1.80986196e-01, 2.85197616e-01,\n","        1.67172104e-01],\n","       [1.95193738e-01, 1.56746626e-01, 2.31057018e-01, 2.42502823e-01,\n","        1.74499825e-01],\n","       [8.45809698e-01, 8.75002295e-02, 6.58882782e-03, 1.49444472e-02,\n","        4.51568328e-02],\n","       [9.14441943e-02, 2.31226683e-01, 9.84131545e-02, 4.71411109e-01,\n","        1.07504830e-01],\n","       [2.07310241e-05, 9.99977946e-01, 8.82113671e-09, 6.37529070e-07,\n","        7.14192765e-07],\n","       [2.01501235e-01, 1.28719613e-01, 2.08959416e-01, 2.83990055e-01,\n","        1.76829621e-01],\n","       [2.09826127e-01, 3.37906592e-02, 3.23881716e-01, 2.64197528e-01,\n","        1.68304011e-01],\n","       [1.45659607e-03, 9.95006919e-01, 1.05070307e-04, 2.78224819e-03,\n","        6.49132708e-04],\n","       [2.14782000e-01, 3.79298292e-02, 3.24729115e-01, 2.48724073e-01,\n","        1.73834890e-01],\n","       [1.94670111e-01, 1.10300116e-01, 2.51131386e-01, 2.54814357e-01,\n","        1.89084038e-01],\n","       [2.11842774e-07, 9.99999762e-01, 1.21617383e-10, 4.73903405e-08,\n","        2.09681357e-08],\n","       [4.66875917e-06, 9.99993324e-01, 1.34642797e-09, 8.70750583e-08,\n","        1.82799693e-06],\n","       [1.13363210e-02, 8.07692409e-02, 1.76547971e-02, 8.64430726e-01,\n","        2.58088429e-02],\n","       [1.66830540e-01, 1.58247977e-01, 2.66475856e-01, 1.93582624e-01,\n","        2.14862972e-01],\n","       [2.97805578e-01, 2.94037521e-01, 1.20766021e-01, 1.17981464e-01,\n","        1.69409335e-01],\n","       [8.46147597e-01, 8.76614526e-02, 6.46118401e-03, 1.47239957e-02,\n","        4.50058468e-02],\n","       [2.10114047e-01, 3.39318328e-02, 3.24062049e-01, 2.63490766e-01,\n","        1.68401331e-01],\n","       [2.06817448e-01, 1.35827988e-01, 2.18896404e-01, 2.72161603e-01,\n","        1.66296527e-01],\n","       [6.96292073e-02, 8.29889596e-01, 1.15734860e-02, 5.94915524e-02,\n","        2.94161458e-02],\n","       [1.72199294e-01, 1.21237330e-01, 2.99870819e-01, 1.89613134e-01,\n","        2.17079386e-01],\n","       [1.74962848e-01, 7.86954984e-02, 2.59768575e-01, 2.96528488e-01,\n","        1.90044552e-01],\n","       [2.15480283e-01, 3.94498482e-02, 3.24534237e-01, 2.45027214e-01,\n","        1.75508380e-01],\n","       [1.22878514e-01, 2.12418616e-01, 1.27205014e-01, 4.10129368e-01,\n","        1.27368510e-01],\n","       [1.38201252e-01, 7.71028250e-02, 3.57280344e-01, 1.80409878e-01,\n","        2.47005656e-01],\n","       [9.59151657e-04, 9.98581529e-01, 7.90832655e-06, 3.27936024e-04,\n","        1.23452017e-04],\n","       [9.95254666e-02, 3.52048650e-02, 4.71087128e-01, 1.43622890e-01,\n","        2.50559688e-01],\n","       [2.77970412e-06, 9.99997139e-01, 3.99160371e-10, 3.25656302e-08,\n","        1.25491198e-07],\n","       [2.01843187e-01, 1.59458786e-01, 2.01544076e-01, 2.64399201e-01,\n","        1.72754735e-01],\n","       [1.99657544e-01, 9.18005779e-02, 2.20869988e-01, 3.22196245e-01,\n","        1.65475667e-01],\n","       [1.41814519e-02, 2.52675614e-04, 3.75528377e-03, 4.38807253e-03,\n","        9.77422476e-01],\n","       [1.58001549e-05, 9.99983430e-01, 3.60382457e-09, 3.15919493e-07,\n","        3.97301392e-07],\n","       [1.82682484e-01, 1.18692234e-01, 2.99077779e-01, 1.80343449e-01,\n","        2.19204038e-01],\n","       [2.09489331e-01, 5.85433953e-02, 3.77773404e-01, 1.48068324e-01,\n","        2.06125602e-01],\n","       [2.02804744e-01, 1.43011898e-01, 2.24570185e-01, 2.46427938e-01,\n","        1.83185220e-01],\n","       [1.71051830e-01, 1.14864856e-01, 3.03553492e-01, 1.91163704e-01,\n","        2.19366089e-01],\n","       [1.39663875e-01, 1.03882082e-01, 3.44186932e-01, 1.66081920e-01,\n","        2.46185228e-01],\n","       [5.59668348e-04, 9.99141335e-01, 2.92634286e-06, 2.31013237e-05,\n","        2.72919686e-04],\n","       [2.15364769e-01, 3.93700637e-02, 3.24543953e-01, 2.45347217e-01,\n","        1.75374061e-01],\n","       [1.71753556e-01, 3.34427394e-02, 4.63038176e-01, 1.02021024e-01,\n","        2.29744464e-01],\n","       [1.54447570e-01, 1.96127623e-01, 1.64941385e-01, 3.31901819e-01,\n","        1.52581558e-01],\n","       [1.61115080e-01, 1.85397729e-01, 1.59865826e-01, 3.42027485e-01,\n","        1.51593819e-01],\n","       [1.95324391e-01, 1.22028910e-01, 2.56215811e-01, 2.31855050e-01,\n","        1.94575772e-01],\n","       [2.88865152e-07, 9.99999523e-01, 4.45668835e-10, 1.78647596e-07,\n","        6.76400091e-08],\n","       [1.70677215e-01, 7.88151547e-02, 3.27739090e-01, 2.08550885e-01,\n","        2.14217633e-01],\n","       [1.85307831e-01, 2.77205333e-02, 4.58672941e-01, 1.09211884e-01,\n","        2.19086826e-01],\n","       [1.66745335e-01, 8.46820176e-02, 2.64801979e-01, 2.80956000e-01,\n","        2.02814728e-01],\n","       [2.07504973e-01, 3.20534073e-02, 3.22155029e-01, 2.72124678e-01,\n","        1.66161835e-01],\n","       [3.32062803e-02, 7.92614162e-01, 1.86619870e-02, 1.22322291e-01,\n","        3.31953764e-02],\n","       [1.09967224e-01, 2.40895942e-01, 1.15103632e-01, 4.13341552e-01,\n","        1.20691694e-01],\n","       [2.09659333e-06, 9.99996662e-01, 4.85117813e-09, 9.16444947e-07,\n","        2.70249302e-07],\n","       [1.63894117e-01, 1.39890537e-01, 1.99213177e-01, 3.29126149e-01,\n","        1.67875990e-01],\n","       [5.32704532e-01, 1.12307020e-01, 1.34028137e-01, 8.68034065e-02,\n","        1.34156913e-01],\n","       [1.65646330e-01, 5.72193004e-02, 4.34927106e-01, 1.55558750e-01,\n","        1.86648577e-01],\n","       [5.12862498e-05, 9.99940157e-01, 1.13109010e-07, 3.23172344e-06,\n","        5.26253643e-06],\n","       [2.01437235e-01, 2.84574851e-02, 3.11786950e-01, 2.99764484e-01,\n","        1.58553779e-01],\n","       [1.24248989e-01, 1.99205264e-01, 4.46702987e-02, 5.72069824e-01,\n","        5.98056801e-02],\n","       [2.15134889e-01, 3.83015536e-02, 3.24775517e-01, 2.47553989e-01,\n","        1.74234107e-01],\n","       [1.01540472e-05, 9.99988914e-01, 3.49853968e-09, 1.84358342e-07,\n","        6.66075778e-07],\n","       [1.34343636e-05, 9.99985337e-01, 7.24637328e-09, 3.75810714e-07,\n","        8.06278592e-07],\n","       [1.60909280e-01, 1.67356431e-01, 1.64256305e-01, 3.52029860e-01,\n","        1.55448124e-01],\n","       [3.74191848e-04, 9.99564111e-01, 1.21105029e-06, 2.71207791e-05,\n","        3.33165226e-05],\n","       [3.17807287e-01, 3.15017179e-02, 3.87258381e-01, 8.67990926e-02,\n","        1.76633611e-01],\n","       [1.51581988e-01, 1.96268469e-01, 1.64749384e-01, 3.36567432e-01,\n","        1.50832742e-01],\n","       [2.21805640e-05, 9.99975204e-01, 2.13858486e-09, 2.50215095e-07,\n","        2.35394396e-06],\n","       [1.89802751e-01, 1.45741865e-01, 2.43519247e-01, 2.27962837e-01,\n","        1.92973316e-01],\n","       [2.10209236e-01, 3.42814252e-02, 3.24107170e-01, 2.62413651e-01,\n","        1.68988526e-01],\n","       [7.84697022e-06, 9.99991894e-01, 1.25026700e-09, 1.50208251e-07,\n","        1.59842216e-07],\n","       [2.15413585e-01, 3.89570631e-02, 3.24813366e-01, 2.45842904e-01,\n","        1.74973115e-01],\n","       [1.94982484e-01, 1.41558230e-01, 2.44321451e-01, 2.24692509e-01,\n","        1.94445297e-01],\n","       [1.92425206e-01, 1.43510252e-01, 2.40671366e-01, 2.29262739e-01,\n","        1.94130555e-01],\n","       [2.15305910e-01, 3.86363454e-02, 3.24867755e-01, 2.46589541e-01,\n","        1.74600348e-01],\n","       [2.06128567e-01, 1.36951044e-01, 2.16854826e-01, 2.73875982e-01,\n","        1.66189522e-01],\n","       [2.33410974e-04, 9.99706447e-01, 2.10233088e-06, 2.10394483e-05,\n","        3.69367554e-05],\n","       [1.28051643e-05, 9.99986887e-01, 6.31302066e-10, 5.65440708e-08,\n","        3.26899681e-07],\n","       [1.60375714e-01, 8.61809701e-02, 2.13095278e-01, 3.71070892e-01,\n","        1.69277191e-01],\n","       [5.63679449e-03, 9.92504954e-01, 8.74442776e-05, 7.53524306e-04,\n","        1.01731403e-03],\n","       [1.65851578e-01, 6.16867542e-02, 2.25351304e-01, 3.83308142e-01,\n","        1.63802311e-01],\n","       [1.72920987e-01, 1.18925817e-01, 3.03874791e-01, 1.85583606e-01,\n","        2.18694821e-01],\n","       [2.02068359e-01, 1.31941274e-01, 2.34753221e-01, 2.43884966e-01,\n","        1.87352166e-01],\n","       [1.25225499e-01, 1.97383732e-01, 1.29122138e-01, 4.00551289e-01,\n","        1.47717342e-01],\n","       [1.75070941e-01, 6.60462072e-03, 4.33860958e-01, 5.40714934e-02,\n","        3.30391943e-01],\n","       [3.32363561e-05, 9.99959588e-01, 8.02332707e-08, 3.87073169e-06,\n","        3.31226488e-06],\n","       [1.69927061e-01, 1.24537371e-01, 2.92361647e-01, 1.95647791e-01,\n","        2.17526168e-01],\n","       [1.47843868e-01, 2.04201981e-01, 1.49816677e-01, 3.48053366e-01,\n","        1.50084153e-01],\n","       [1.84447348e-01, 1.13729320e-01, 2.83269942e-01, 2.15350449e-01,\n","        2.03202918e-01],\n","       [5.32197760e-07, 9.99999404e-01, 7.21560103e-11, 9.44949097e-09,\n","        2.35053736e-08],\n","       [2.14347303e-01, 3.75620462e-02, 3.24724942e-01, 2.49950603e-01,\n","        1.73415095e-01],\n","       [4.64624390e-02, 2.64895499e-01, 2.87308656e-02, 6.21986151e-01,\n","        3.79250087e-02],\n","       [2.06176072e-01, 4.19986784e-01, 9.70335454e-02, 1.21040501e-01,\n","        1.55763030e-01],\n","       [8.91859233e-02, 1.89555347e-01, 1.03306182e-01, 4.88442421e-01,\n","        1.29510120e-01],\n","       [2.67037079e-02, 8.68044868e-02, 3.54296938e-02, 8.03671002e-01,\n","        4.73911576e-02],\n","       [1.40372053e-01, 2.18438879e-02, 5.49780428e-01, 1.22028038e-01,\n","        1.65975600e-01],\n","       [1.11801036e-01, 2.17371568e-01, 1.14198849e-01, 4.27067727e-01,\n","        1.29560798e-01],\n","       [1.21659627e-02, 8.78922522e-01, 7.79086957e-03, 8.28468055e-02,\n","        1.82738043e-02],\n","       [8.16220825e-04, 9.97482121e-01, 3.45485387e-05, 1.39208126e-03,\n","        2.75120081e-04],\n","       [1.70759663e-01, 1.63757622e-01, 2.60875106e-01, 1.92432299e-01,\n","        2.12175295e-01],\n","       [8.41329917e-02, 2.06376076e-01, 1.06144212e-01, 5.11664391e-01,\n","        9.16822702e-02],\n","       [1.16293449e-02, 1.42365590e-01, 7.14357011e-03, 8.28453004e-01,\n","        1.04084946e-02],\n","       [2.15136632e-01, 3.99820842e-02, 3.22809726e-01, 2.46768460e-01,\n","        1.75303057e-01],\n","       [1.10134177e-01, 7.02165246e-01, 2.98085604e-02, 9.89138782e-02,\n","        5.89781292e-02],\n","       [2.08413169e-01, 3.31416093e-02, 3.21776152e-01, 2.69413501e-01,\n","        1.67255566e-01],\n","       [1.90849453e-01, 1.60395861e-01, 1.81195959e-01, 3.04051459e-01,\n","        1.63507327e-01],\n","       [1.69416025e-01, 1.89435706e-01, 1.66489452e-01, 3.04731965e-01,\n","        1.69926807e-01],\n","       [1.22033566e-01, 5.80132008e-02, 3.71216029e-01, 2.00305849e-01,\n","        2.48431325e-01],\n","       [1.25676140e-01, 5.18408008e-02, 4.39229518e-01, 1.20543547e-01,\n","        2.62710005e-01],\n","       [2.15176314e-01, 3.83435227e-02, 3.24801117e-01, 2.47415155e-01,\n","        1.74263909e-01],\n","       [6.05656244e-02, 8.83062124e-01, 6.13682764e-03, 2.66428683e-02,\n","        2.35925354e-02],\n","       [1.77915812e-01, 9.32366475e-02, 2.47333586e-01, 2.88900733e-01,\n","        1.92613304e-01],\n","       [1.72608301e-01, 8.28057975e-02, 3.43787342e-01, 1.76696345e-01,\n","        2.24102125e-01],\n","       [2.08532438e-01, 3.27439457e-02, 3.22924644e-01, 2.68767774e-01,\n","        1.67031273e-01],\n","       [2.11994827e-01, 3.56702544e-02, 3.24343711e-01, 2.56930262e-01,\n","        1.71060845e-01]], dtype=float32)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["y_pred"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["array([1, 2, 2, 2, 3, 3, 2, 1, 3, 0, 2, 2, 1, 2, 1, 0, 1, 2, 2, 2, 1, 2,\n","       2, 2, 2, 2, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2, 1, 2, 2, 4,\n","       2, 2, 3, 0, 0, 1, 2, 2, 2, 2, 2, 1, 1, 1, 3, 0, 3, 2, 3, 2, 3, 3,\n","       2, 1, 1, 1, 2, 2, 3, 2, 2, 3, 3, 1, 2, 2, 3, 1, 1, 2, 3, 3, 0, 3,\n","       1, 3, 2, 1, 2, 3, 1, 1, 3, 2, 0, 0, 2, 3, 1, 2, 3, 2, 3, 2, 1, 2,\n","       1, 3, 3, 4, 1, 2, 2, 3, 2, 2, 1, 2, 2, 3, 3, 2, 1, 2, 2, 3, 2, 1,\n","       3, 1, 3, 0, 2, 1, 2, 3, 2, 1, 1, 3, 1, 2, 3, 1, 2, 2, 1, 2, 2, 2,\n","       2, 3, 1, 1, 3, 1, 3, 2, 3, 3, 2, 1, 2, 3, 2, 1, 2, 3, 1, 3, 3, 2,\n","       3, 1, 1, 2, 3, 3, 2, 1, 2, 3, 3, 2, 2, 2, 1, 3, 2, 2, 2],\n","      dtype=int64)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["y_pred_classes"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy Score: 0.5794871794871795\n"]}],"source":["accuracy = accuracy_score(y_test, y_pred_classes)\n","print(f'Accuracy Score: {accuracy}')"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.78      0.21      0.33        33\n","           1       0.98      0.80      0.88        56\n","           2       0.34      0.81      0.48        37\n","           3       0.58      0.64      0.61        45\n","           4       1.00      0.08      0.15        24\n","\n","    accuracy                           0.58       195\n","   macro avg       0.74      0.51      0.49       195\n","weighted avg       0.73      0.58      0.56       195\n","\n"]}],"source":["class_report = classification_report(y_test, y_pred_classes)\n","print('Classification Report:\\n', class_report)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"]}],"source":["y_pred = model.predict(x_train)\n","y_pred_classes = y_pred.argmax(axis=1)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy Score: 0.5655526992287918\n"]}],"source":["accuracy = accuracy_score(y_train, y_pred_classes)\n","print(f'Accuracy Score: {accuracy}')"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.80      0.29      0.43       141\n","           1       0.98      0.75      0.85       173\n","           2       0.40      0.84      0.54       173\n","           3       0.52      0.66      0.58       177\n","           4       1.00      0.05      0.10       114\n","\n","    accuracy                           0.57       778\n","   macro avg       0.74      0.52      0.50       778\n","weighted avg       0.72      0.57      0.54       778\n","\n"]}],"source":["class_report = classification_report(y_train, y_pred_classes)\n","print('Classification Report:\\n', class_report)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4572327,"sourceId":7811597,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":4}
