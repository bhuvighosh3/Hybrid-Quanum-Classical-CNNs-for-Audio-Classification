{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-11T08:14:20.494188Z","iopub.status.busy":"2024-03-11T08:14:20.493768Z","iopub.status.idle":"2024-03-11T08:14:36.550773Z","shell.execute_reply":"2024-03-11T08:14:36.549452Z","shell.execute_reply.started":"2024-03-11T08:14:20.494156Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Yash Thakar\\AppData\\Local\\Temp\\ipykernel_8076\\3230018081.py:1: DeprecationWarning: \n","Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n","(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n","but was not found to be installed on your system.\n","If this would cause problems for you,\n","please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n","        \n","  import pandas as pd\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","from sklearn.metrics import accuracy_score, classification_report\n","from keras.models import Sequential\n","from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n","from sklearn.model_selection import train_test_split\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["df_x = pd.read_csv(\"pre_processed_data/df_x_n_mfcc52_ae10.csv\") "]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["df_y = pd.read_csv(\"pre_processed_data/df_y_n_mfcc52_ae10.csv\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["x = np.array(df_x).reshape(-1, 10, 1)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Yash Thakar\\PROGRAMMING\\Quantum\\env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]}],"source":["label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(df_y)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[  0   1   2   3   4]\n"," [174 212 210 222 138]]\n"]}],"source":["unique_elements, counts_elements = np.unique(y_encoded, return_counts=True)\n","print(np.asarray((unique_elements, counts_elements)))"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, \n","                                                    test_size=0.2, random_state = 42)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Yash Thakar\\PROGRAMMING\\Quantum\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.2112 - loss: 6.5412 - val_accuracy: 0.1615 - val_loss: 1.7840\n","Epoch 2/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1746 - loss: 3.3097 - val_accuracy: 0.3125 - val_loss: 1.5297\n","Epoch 3/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2085 - loss: 2.2680 - val_accuracy: 0.2500 - val_loss: 1.5701\n","Epoch 4/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2478 - loss: 1.7911 - val_accuracy: 0.2656 - val_loss: 1.5502\n","Epoch 5/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2165 - loss: 1.7379 - val_accuracy: 0.2812 - val_loss: 1.5457\n","Epoch 6/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2270 - loss: 1.6702 - val_accuracy: 0.3125 - val_loss: 1.5452\n","Epoch 7/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2183 - loss: 1.6458 - val_accuracy: 0.3438 - val_loss: 1.5124\n","Epoch 8/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2614 - loss: 1.5731 - val_accuracy: 0.2708 - val_loss: 1.4751\n","Epoch 9/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2673 - loss: 1.6401 - val_accuracy: 0.3177 - val_loss: 1.4798\n","Epoch 10/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2671 - loss: 1.5504 - val_accuracy: 0.3021 - val_loss: 1.4714\n","Epoch 11/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.2857 - loss: 1.5406 - val_accuracy: 0.4219 - val_loss: 1.4746\n","Epoch 12/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.3222 - loss: 1.5043 - val_accuracy: 0.3854 - val_loss: 1.4469\n","Epoch 13/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.2524 - loss: 1.5419 - val_accuracy: 0.4167 - val_loss: 1.4590\n","Epoch 14/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2473 - loss: 1.5617 - val_accuracy: 0.3594 - val_loss: 1.4517\n","Epoch 15/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2966 - loss: 1.5212 - val_accuracy: 0.3802 - val_loss: 1.4462\n","Epoch 16/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2801 - loss: 1.5199 - val_accuracy: 0.3281 - val_loss: 1.4224\n","Epoch 17/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.2990 - loss: 1.4840 - val_accuracy: 0.3646 - val_loss: 1.4254\n","Epoch 18/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2701 - loss: 1.5244 - val_accuracy: 0.3958 - val_loss: 1.4045\n","Epoch 19/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3464 - loss: 1.4869 - val_accuracy: 0.4010 - val_loss: 1.4208\n","Epoch 20/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3031 - loss: 1.5073 - val_accuracy: 0.4583 - val_loss: 1.4075\n","Epoch 21/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.2925 - loss: 1.4829 - val_accuracy: 0.3125 - val_loss: 1.4293\n","Epoch 22/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.3179 - loss: 1.4916 - val_accuracy: 0.3490 - val_loss: 1.4200\n","Epoch 23/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3140 - loss: 1.4853 - val_accuracy: 0.3646 - val_loss: 1.3997\n","Epoch 24/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3469 - loss: 1.4641 - val_accuracy: 0.3281 - val_loss: 1.4273\n","Epoch 25/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3454 - loss: 1.4882 - val_accuracy: 0.4010 - val_loss: 1.3919\n","Epoch 26/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3187 - loss: 1.4660 - val_accuracy: 0.4479 - val_loss: 1.3886\n","Epoch 27/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3145 - loss: 1.4974 - val_accuracy: 0.3698 - val_loss: 1.3989\n","Epoch 28/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3364 - loss: 1.4705 - val_accuracy: 0.4115 - val_loss: 1.4051\n","Epoch 29/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3357 - loss: 1.4839 - val_accuracy: 0.4010 - val_loss: 1.3846\n","Epoch 30/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3279 - loss: 1.4550 - val_accuracy: 0.4167 - val_loss: 1.3728\n","Epoch 31/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3223 - loss: 1.4690 - val_accuracy: 0.3646 - val_loss: 1.3660\n","Epoch 32/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3467 - loss: 1.4490 - val_accuracy: 0.4792 - val_loss: 1.3963\n","Epoch 33/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3428 - loss: 1.4562 - val_accuracy: 0.4062 - val_loss: 1.3701\n","Epoch 34/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.3344 - loss: 1.4759 - val_accuracy: 0.3906 - val_loss: 1.4004\n","Epoch 35/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3167 - loss: 1.4480 - val_accuracy: 0.3958 - val_loss: 1.3605\n","Epoch 36/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3027 - loss: 1.4764 - val_accuracy: 0.4010 - val_loss: 1.3926\n","Epoch 37/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.3160 - loss: 1.4713 - val_accuracy: 0.3594 - val_loss: 1.3700\n","Epoch 38/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3561 - loss: 1.4516 - val_accuracy: 0.3854 - val_loss: 1.3707\n","Epoch 39/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3618 - loss: 1.4607 - val_accuracy: 0.3958 - val_loss: 1.3927\n","Epoch 40/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3031 - loss: 1.4629 - val_accuracy: 0.3958 - val_loss: 1.3616\n","Epoch 41/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.3424 - loss: 1.4574 - val_accuracy: 0.3906 - val_loss: 1.3631\n","Epoch 42/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.3625 - loss: 1.4654 - val_accuracy: 0.4167 - val_loss: 1.3653\n","Epoch 43/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.3672 - loss: 1.4236 - val_accuracy: 0.4479 - val_loss: 1.3557\n","Epoch 44/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3676 - loss: 1.4493 - val_accuracy: 0.4010 - val_loss: 1.3708\n","Epoch 45/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.3335 - loss: 1.4444 - val_accuracy: 0.4062 - val_loss: 1.3619\n","Epoch 46/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3181 - loss: 1.4334 - val_accuracy: 0.4323 - val_loss: 1.3434\n","Epoch 47/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3541 - loss: 1.4162 - val_accuracy: 0.3802 - val_loss: 1.3651\n","Epoch 48/100\n","\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3435 - loss: 1.4560 - val_accuracy: 0.3854 - val_loss: 1.4492\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x12887f9ed90>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Create the model\n","model = Sequential()\n","\n","# Add convolutional layers\n","model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(13, 1)))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Conv1D(64, kernel_size=3, activation='relu'))\n","model.add(MaxPooling1D(pool_size=2))\n","\n","# Flatten the output of the convolutional layers\n","model.add(Flatten())\n","\n","# Add dense layers\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.3))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dropout(0.3))\n","model.add(Dense(5, activation='softmax')) \n","\n","\n","# Compile the model\n","optimiser = tf.keras.optimizers.Adam(learning_rate = 0.0002)\n","cb = [EarlyStopping(patience=10,monitor='accuracy',mode='max',restore_best_weights=True)]\n","model.compile(optimizer=optimiser, loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","# Train the model\n","model.fit(x_train, y_train, epochs=100, batch_size=16, validation_data=(x_test, y_test), callbacks = cb)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  \n"]}],"source":["y_pred = model.predict(x_test)\n","y_pred_classes = y_pred.argmax(axis=1)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["array([[4.22859401e-01, 4.87801999e-01, 4.63815667e-02, 1.92970727e-02,\n","        2.36600060e-02],\n","       [2.54328936e-01, 3.50277275e-01, 1.57334536e-01, 1.25444070e-01,\n","        1.12615198e-01],\n","       [2.83775002e-01, 3.66290361e-01, 1.37325540e-01, 1.08559720e-01,\n","        1.04049422e-01],\n","       [1.03417553e-01, 1.49081543e-01, 2.56821036e-01, 3.01928729e-01,\n","        1.88751101e-01],\n","       [1.92291304e-01, 1.89072236e-01, 2.11385205e-01, 2.24470422e-01,\n","        1.82780817e-01],\n","       [1.15764320e-01, 1.61937043e-01, 2.47621775e-01, 2.84741044e-01,\n","        1.89935863e-01],\n","       [3.96954000e-01, 4.78875726e-01, 6.09072745e-02, 2.94132698e-02,\n","        3.38497497e-02],\n","       [3.39923054e-01, 4.10991222e-01, 1.06481731e-01, 6.94040954e-02,\n","        7.31999129e-02],\n","       [1.01609878e-01, 1.47152841e-01, 2.58176088e-01, 3.04554075e-01,\n","        1.88507140e-01],\n","       [1.26661777e-01, 2.01992676e-01, 2.36749753e-01, 2.67123282e-01,\n","        1.67472497e-01],\n","       [9.68859121e-02, 1.42053932e-01, 2.61725515e-01, 3.11558515e-01,\n","        1.87776119e-01],\n","       [2.88028747e-01, 3.83590221e-01, 1.32881552e-01, 1.00551002e-01,\n","        9.49484557e-02],\n","       [1.90564126e-01, 1.77793145e-01, 2.18312547e-01, 2.32110426e-01,\n","        1.81219727e-01],\n","       [1.35988072e-01, 2.03822687e-01, 2.30563894e-01, 2.55951911e-01,\n","        1.73673496e-01],\n","       [1.99632257e-01, 2.92843491e-01, 1.92875430e-01, 1.74139351e-01,\n","        1.40509531e-01],\n","       [1.07550524e-01, 1.53445691e-01, 2.53730357e-01, 2.96034932e-01,\n","        1.89238474e-01],\n","       [4.71893251e-01, 4.94511545e-01, 1.92742497e-02, 5.94652770e-03,\n","        8.37444700e-03],\n","       [1.27386406e-01, 2.02681348e-01, 2.36216664e-01, 2.66258180e-01,\n","        1.67457417e-01],\n","       [1.22694626e-01, 2.00703800e-01, 2.39449486e-01, 2.72112429e-01,\n","        1.65039688e-01],\n","       [2.59295613e-01, 3.35213780e-01, 1.52999789e-01, 1.30535781e-01,\n","        1.21955097e-01],\n","       [1.00909881e-01, 1.46402657e-01, 2.58701354e-01, 3.05578679e-01,\n","        1.88407436e-01],\n","       [1.57851875e-01, 9.62683111e-02, 2.92581230e-01, 3.09462607e-01,\n","        1.43835902e-01],\n","       [4.27117020e-01, 4.85615969e-01, 4.51938435e-02, 1.88284218e-02,\n","        2.32447460e-02],\n","       [3.07146102e-01, 4.15751457e-01, 1.15130797e-01, 8.25706124e-02,\n","        7.94009790e-02],\n","       [1.00206904e-01, 1.45647451e-01, 2.59229064e-01, 3.06612253e-01,\n","        1.88304380e-01],\n","       [4.48480546e-01, 4.70363408e-01, 4.04772051e-02, 1.79621335e-02,\n","        2.27167979e-02],\n","       [1.41870365e-01, 2.16919497e-01, 2.29268909e-01, 2.44081989e-01,\n","        1.67859286e-01],\n","       [1.09335862e-01, 1.64339498e-01, 2.51988053e-01, 2.92082012e-01,\n","        1.82254508e-01],\n","       [1.20477945e-01, 1.82959437e-01, 2.42720246e-01, 2.74862498e-01,\n","        1.78979874e-01],\n","       [1.15258895e-01, 1.61421373e-01, 2.47996137e-01, 2.85420686e-01,\n","        1.89902827e-01],\n","       [9.77928266e-02, 1.43039465e-01, 2.61043072e-01, 3.10197264e-01,\n","        1.87927380e-01],\n","       [1.61953002e-01, 1.03778735e-01, 2.84508288e-01, 3.01392496e-01,\n","        1.48367465e-01],\n","       [1.05130002e-01, 1.50897399e-01, 2.55539238e-01, 2.99468726e-01,\n","        1.88964695e-01],\n","       [1.96086332e-01, 1.94717720e-01, 2.06761405e-01, 2.21356988e-01,\n","        1.81077570e-01],\n","       [3.32835943e-01, 5.57749629e-01, 5.32098971e-02, 2.84070298e-02,\n","        2.77974997e-02],\n","       [4.15064394e-01, 4.60562587e-01, 5.94876781e-02, 2.96465065e-02,\n","        3.52388993e-02],\n","       [1.13876037e-01, 1.68011650e-01, 2.48666003e-01, 2.85983562e-01,\n","        1.83462799e-01],\n","       [1.23250559e-01, 2.00323075e-01, 2.39127517e-01, 2.71329284e-01,\n","        1.65969580e-01],\n","       [1.02986611e-01, 1.48622796e-01, 2.57143945e-01, 3.02552015e-01,\n","        1.88694641e-01],\n","       [1.08905375e-01, 1.54862761e-01, 2.52719611e-01, 2.94134587e-01,\n","        1.89377636e-01],\n","       [2.11319417e-01, 3.00634921e-01, 1.88834026e-01, 1.63049862e-01,\n","        1.36161819e-01],\n","       [1.34853542e-01, 2.05776751e-01, 2.31127262e-01, 2.57387489e-01,\n","        1.70855001e-01],\n","       [3.60139966e-01, 4.57981706e-01, 8.28653947e-02, 4.79108877e-02,\n","        5.11020981e-02],\n","       [1.09880447e-01, 1.55878559e-01, 2.51992911e-01, 2.92776316e-01,\n","        1.89471751e-01],\n","       [1.09069370e-01, 1.55033842e-01, 2.52597362e-01, 2.93905556e-01,\n","        1.89393848e-01],\n","       [1.23257518e-01, 1.95967719e-01, 2.39491045e-01, 2.71054417e-01,\n","        1.70229346e-01],\n","       [3.64036202e-01, 4.62265700e-01, 7.98640326e-02, 4.52542379e-02,\n","        4.85798381e-02],\n","       [3.89455855e-01, 4.44309503e-01, 7.56306276e-02, 4.24768664e-02,\n","        4.81271259e-02],\n","       [1.08000703e-01, 1.53917238e-01, 2.53394365e-01, 2.95401841e-01,\n","        1.89285845e-01],\n","       [1.68701649e-01, 1.18284695e-01, 2.69829750e-01, 2.86812067e-01,\n","        1.56371936e-01],\n","       [2.74408430e-01, 4.65900213e-01, 1.01955891e-01, 8.37143138e-02,\n","        7.40210488e-02],\n","       [1.00671329e-01, 1.46146610e-01, 2.58880287e-01, 3.05928946e-01,\n","        1.88372865e-01],\n","       [1.09064631e-01, 1.55028924e-01, 2.52600759e-01, 2.93912143e-01,\n","        1.89393446e-01],\n","       [1.14779770e-01, 1.60931706e-01, 2.48351410e-01, 2.86066800e-01,\n","        1.89870253e-01],\n","       [4.79516119e-01, 4.83732134e-01, 2.06307899e-02, 6.70131017e-03,\n","        9.41960979e-03],\n","       [3.41937333e-01, 4.44595307e-01, 9.40244794e-02, 5.88280223e-02,\n","        6.06148019e-02],\n","       [1.51820704e-01, 8.52743685e-02, 3.04613471e-01, 3.21744084e-01,\n","        1.36547357e-01],\n","       [1.07351452e-01, 1.57632127e-01, 2.53770918e-01, 2.95693159e-01,\n","        1.85552344e-01],\n","       [1.12543598e-01, 1.58635706e-01, 2.50011414e-01, 2.89105743e-01,\n","        1.89703479e-01],\n","       [1.13047391e-01, 1.59154445e-01, 2.49637246e-01, 2.88417757e-01,\n","        1.89743191e-01],\n","       [1.27735272e-01, 2.08954155e-01, 2.39871010e-01, 2.62335807e-01,\n","        1.61103740e-01],\n","       [1.01993419e-01, 1.47563100e-01, 2.57888317e-01, 3.03994596e-01,\n","        1.88560605e-01],\n","       [1.03334852e-01, 1.61846355e-01, 2.56187648e-01, 2.99790412e-01,\n","        1.78840682e-01],\n","       [1.58182353e-01, 2.40639657e-01, 2.20016941e-01, 2.22316906e-01,\n","        1.58844158e-01],\n","       [1.30470619e-01, 2.00169042e-01, 2.34424651e-01, 2.62332410e-01,\n","        1.72603279e-01],\n","       [1.47935003e-01, 2.28145808e-01, 2.23476022e-01, 2.36149311e-01,\n","        1.64293855e-01],\n","       [2.84464091e-01, 3.77371520e-01, 1.35631144e-01, 1.04245372e-01,\n","        9.82878730e-02],\n","       [3.66324127e-01, 4.63473588e-01, 7.85879493e-02, 4.40766774e-02,\n","        4.75376211e-02],\n","       [1.25852346e-01, 1.80473566e-01, 2.39669293e-01, 2.69881517e-01,\n","        1.84123352e-01],\n","       [1.14900030e-01, 1.61054596e-01, 2.48262241e-01, 2.85904557e-01,\n","        1.89878568e-01],\n","       [1.77995190e-01, 2.60993421e-01, 2.09578529e-01, 1.98857099e-01,\n","        1.52575731e-01],\n","       [1.20954365e-01, 1.92461058e-01, 2.41290703e-01, 2.73759633e-01,\n","        1.71534255e-01],\n","       [1.93641216e-01, 2.80033737e-01, 2.01086879e-01, 1.80686623e-01,\n","        1.44551545e-01],\n","       [4.82401587e-02, 6.10230817e-03, 4.49958861e-01, 4.60082948e-01,\n","        3.56156975e-02],\n","       [1.74169004e-01, 1.30481124e-01, 2.57844985e-01, 2.74890453e-01,\n","        1.62614509e-01],\n","       [9.64338481e-02, 1.41561374e-01, 2.62065709e-01, 3.12240243e-01,\n","        1.87698871e-01],\n","       [1.01031058e-01, 1.46532685e-01, 2.58610338e-01, 3.05400997e-01,\n","        1.88424930e-01],\n","       [1.22271664e-01, 2.08963066e-01, 2.45709106e-01, 2.67545193e-01,\n","        1.55510962e-01],\n","       [1.82633922e-01, 1.55080810e-01, 2.36326650e-01, 2.52846718e-01,\n","        1.73111856e-01],\n","       [1.92596436e-01, 2.61933565e-01, 1.98589042e-01, 1.88797101e-01,\n","        1.58083797e-01],\n","       [1.26911044e-01, 1.92410320e-01, 2.37469628e-01, 2.66253620e-01,\n","        1.76955417e-01],\n","       [2.41290659e-01, 3.13692510e-01, 1.66125387e-01, 1.45621181e-01,\n","        1.33270279e-01],\n","       [2.65062302e-01, 3.54567766e-01, 1.44489348e-01, 1.22274235e-01,\n","        1.13606341e-01],\n","       [4.99471985e-02, 6.92060776e-03, 4.48892266e-01, 4.56251889e-01,\n","        3.79880480e-02],\n","       [1.11643128e-01, 1.57706290e-01, 2.50680774e-01, 2.90340483e-01,\n","        1.89629272e-01],\n","       [1.28861353e-01, 4.51917872e-02, 3.51842016e-01, 3.67442459e-01,\n","        1.06662296e-01],\n","       [2.18316868e-01, 2.93520302e-01, 1.81586906e-01, 1.63190588e-01,\n","        1.43385351e-01],\n","       [1.92078471e-01, 1.84254095e-01, 2.14060053e-01, 2.27778286e-01,\n","        1.81829050e-01],\n","       [9.15824249e-02, 1.36224687e-01, 2.65722871e-01, 3.19686472e-01,\n","        1.86783552e-01],\n","       [1.60063222e-01, 6.68368712e-02, 3.14165056e-01, 3.27735037e-01,\n","        1.31199777e-01],\n","       [1.24023281e-01, 5.13545014e-02, 3.50332648e-01, 3.66207629e-01,\n","        1.08082026e-01],\n","       [1.44098029e-01, 2.21486479e-01, 2.26238027e-01, 2.40935534e-01,\n","        1.67242005e-01],\n","       [9.84733403e-02, 1.43776894e-01, 2.60531455e-01, 3.09180945e-01,\n","        1.88037351e-01],\n","       [1.15056932e-01, 1.61215022e-01, 2.48145983e-01, 2.85692871e-01,\n","        1.89889267e-01],\n","       [2.40476236e-01, 3.16923112e-01, 1.66818440e-01, 1.44559145e-01,\n","        1.31223097e-01],\n","       [1.20542146e-01, 1.95767805e-01, 2.41309375e-01, 2.74545163e-01,\n","        1.67835549e-01],\n","       [1.20578840e-01, 1.93187386e-01, 2.41487160e-01, 2.74308532e-01,\n","        1.70438185e-01],\n","       [1.31505400e-01, 1.94475830e-01, 2.34356016e-01, 2.60805964e-01,\n","        1.78856820e-01],\n","       [1.37123212e-01, 2.03944489e-01, 2.29824916e-01, 2.54629701e-01,\n","        1.74477741e-01],\n","       [3.53839010e-01, 4.59118128e-01, 8.46053883e-02, 4.99712564e-02,\n","        5.24661690e-02],\n","       [2.83746839e-01, 3.74845058e-01, 1.34840518e-01, 1.06067695e-01,\n","        1.00499913e-01],\n","       [7.80040473e-02, 1.77882165e-02, 4.14538890e-01, 4.26536053e-01,\n","        6.31327406e-02],\n","       [1.04838692e-01, 1.54035538e-01, 2.55686343e-01, 2.99418300e-01,\n","        1.86021104e-01],\n","       [3.09278607e-01, 4.87104744e-01, 8.69849622e-02, 6.02514967e-02,\n","        5.63801900e-02],\n","       [1.25827819e-01, 1.85339808e-01, 2.39072949e-01, 2.68625706e-01,\n","        1.81133792e-01],\n","       [1.26261920e-01, 2.11044103e-01, 2.42408335e-01, 2.62242377e-01,\n","        1.58043265e-01],\n","       [8.85570981e-03, 2.15311986e-04, 4.98186737e-01, 4.87310708e-01,\n","        5.43142715e-03],\n","       [3.91769931e-02, 4.20177262e-03, 4.61099148e-01, 4.66576815e-01,\n","        2.89452616e-02],\n","       [1.32155031e-01, 1.78093895e-01, 2.35737175e-01, 2.63679147e-01,\n","        1.90334827e-01],\n","       [1.22574791e-01, 1.99191883e-01, 2.39672899e-01, 2.72130519e-01,\n","        1.66429937e-01],\n","       [1.46403909e-01, 7.11523294e-02, 3.17636877e-01, 3.36292624e-01,\n","        1.28514245e-01],\n","       [5.02616286e-01, 4.67075199e-01, 1.70604866e-02, 5.43035008e-03,\n","        7.81762321e-03],\n","       [1.30153582e-01, 2.12041721e-01, 2.39287660e-01, 2.57876396e-01,\n","        1.60640582e-01],\n","       [1.46121621e-01, 2.30563655e-01, 2.25268707e-01, 2.37364992e-01,\n","        1.60681069e-01],\n","       [1.21348321e-01, 1.82608098e-01, 2.42219254e-01, 2.74035096e-01,\n","        1.79789171e-01],\n","       [1.17892742e-01, 1.64099142e-01, 2.46046737e-01, 2.81899661e-01,\n","        1.90061688e-01],\n","       [1.86243027e-01, 1.68688834e-01, 2.25995794e-01, 2.40328819e-01,\n","        1.78743586e-01],\n","       [1.17745362e-01, 1.81345582e-01, 2.44648844e-01, 2.78225660e-01,\n","        1.78034469e-01],\n","       [2.90123552e-01, 3.87398005e-01, 1.31338149e-01, 9.82868895e-02,\n","        9.28533226e-02],\n","       [1.85833752e-01, 1.67473614e-01, 2.26952523e-01, 2.41515160e-01,\n","        1.78224966e-01],\n","       [1.28003955e-01, 2.12051302e-01, 2.40793079e-01, 2.59900391e-01,\n","        1.59251317e-01],\n","       [1.66278154e-01, 2.48558179e-01, 2.16144949e-01, 2.12324664e-01,\n","        1.56694070e-01],\n","       [1.23760171e-01, 2.01613888e-01, 2.38667667e-01, 2.70808846e-01,\n","        1.65149495e-01],\n","       [1.46835014e-01, 2.26338968e-01, 2.23940849e-01, 2.37473696e-01,\n","        1.65411472e-01],\n","       [1.20548807e-01, 1.96143955e-01, 2.41273656e-01, 2.74561375e-01,\n","        1.67472243e-01],\n","       [2.86955923e-01, 3.66646439e-01, 1.36385888e-01, 1.06634229e-01,\n","        1.03377566e-01],\n","       [3.28898013e-01, 4.16166157e-01, 1.08123735e-01, 7.25180507e-02,\n","        7.42941126e-02],\n","       [3.05254102e-01, 4.08222079e-01, 1.17920704e-01, 8.58323276e-02,\n","        8.27708170e-02],\n","       [1.46166131e-01, 2.26699293e-01, 2.24509344e-01, 2.38028124e-01,\n","        1.64597094e-01],\n","       [3.84804666e-01, 4.45282996e-01, 7.58670717e-02, 4.43123244e-02,\n","        4.97328751e-02],\n","       [1.36249468e-01, 2.20030949e-01, 2.32162416e-01, 2.48673514e-01,\n","        1.62883699e-01],\n","       [1.79306865e-01, 2.66525000e-01, 2.09690288e-01, 1.95597097e-01,\n","        1.48880735e-01],\n","       [4.31881994e-01, 4.66643304e-01, 4.97371256e-02, 2.32387949e-02,\n","        2.84987669e-02],\n","       [1.06521890e-01, 1.62272289e-01, 2.54037797e-01, 2.95889050e-01,\n","        1.81278944e-01],\n","       [4.30775493e-01, 4.85748351e-01, 4.33792397e-02, 1.78710204e-02,\n","        2.22258773e-02],\n","       [2.02944458e-01, 2.78461158e-01, 1.92834660e-01, 1.76457793e-01,\n","        1.49301916e-01],\n","       [1.39178559e-01, 2.15021580e-01, 2.31826514e-01, 2.47459531e-01,\n","        1.66513830e-01],\n","       [1.13599695e-01, 1.60632059e-01, 2.49313638e-01, 2.87509680e-01,\n","        1.88944936e-01],\n","       [1.11323908e-01, 1.57376036e-01, 2.50918299e-01, 2.90779769e-01,\n","        1.89601973e-01],\n","       [3.26621026e-01, 4.00482506e-01, 1.14128157e-01, 7.80780837e-02,\n","        8.06902871e-02],\n","       [5.11000395e-01, 4.69135851e-01, 1.17213707e-02, 3.21191852e-03,\n","        4.93040029e-03],\n","       [1.84788749e-01, 1.63204119e-01, 2.30099082e-01, 2.45451197e-01,\n","        1.76456854e-01],\n","       [2.72577792e-01, 3.49956840e-01, 1.45104378e-01, 1.19131416e-01,\n","        1.13229677e-01],\n","       [3.92870575e-01, 5.74086964e-01, 1.84187517e-02, 7.03179417e-03,\n","        7.59189669e-03],\n","       [1.14680491e-01, 1.60830095e-01, 2.48425022e-01, 2.86200911e-01,\n","        1.89863443e-01],\n","       [1.15022220e-01, 1.61291659e-01, 2.48190612e-01, 2.85719454e-01,\n","        1.89776108e-01],\n","       [2.04188704e-01, 2.80711442e-01, 1.92117184e-01, 1.74910739e-01,\n","        1.48071960e-01],\n","       [1.05966263e-01, 1.54064819e-01, 2.54893303e-01, 2.97961056e-01,\n","        1.87114522e-01],\n","       [3.15034419e-01, 3.99065703e-01, 1.18053280e-01, 8.36081952e-02,\n","        8.42383578e-02],\n","       [1.18927330e-01, 2.00481355e-01, 2.41914645e-01, 2.77162284e-01,\n","        1.61514372e-01],\n","       [1.22987762e-01, 2.01481238e-01, 2.39180073e-01, 2.71814138e-01,\n","        1.64536849e-01],\n","       [1.94473729e-01, 1.95147544e-01, 2.07229182e-01, 2.20756263e-01,\n","        1.82393283e-01],\n","       [1.32561520e-01, 2.03803182e-01, 2.32770309e-01, 2.60015428e-01,\n","        1.70849621e-01],\n","       [2.09844276e-01, 1.57383844e-01, 2.21113101e-01, 2.44447693e-01,\n","        1.67211071e-01],\n","       [1.12481691e-01, 1.58571929e-01, 2.50057340e-01, 2.89190441e-01,\n","        1.89698562e-01],\n","       [3.01827013e-01, 3.87519062e-01, 1.25800595e-01, 9.32049081e-02,\n","        9.16484371e-02],\n","       [1.04819886e-01, 1.50569394e-01, 2.55771220e-01, 2.99912244e-01,\n","        1.88927233e-01],\n","       [1.15843095e-01, 1.62017256e-01, 2.47563437e-01, 2.84635305e-01,\n","        1.89940900e-01],\n","       [1.22378275e-01, 1.99056551e-01, 2.39814058e-01, 2.72374570e-01,\n","        1.66376546e-01],\n","       [1.25777259e-01, 1.82502091e-01, 2.39466578e-01, 2.69430310e-01,\n","        1.82823732e-01],\n","       [1.88722953e-01, 1.78583831e-01, 2.18725413e-01, 2.31582105e-01,\n","        1.82385743e-01],\n","       [1.02642864e-01, 1.55951679e-01, 2.57144541e-01, 3.01995814e-01,\n","        1.82265162e-01],\n","       [1.18642077e-01, 1.64856747e-01, 2.45492965e-01, 2.80907273e-01,\n","        1.90100923e-01],\n","       [1.08728215e-01, 1.54677808e-01, 2.52851784e-01, 2.94382244e-01,\n","        1.89359993e-01],\n","       [1.09736264e-01, 3.74773964e-02, 3.72085065e-01, 3.87997776e-01,\n","        9.27034914e-02],\n","       [1.03455983e-01, 1.62005052e-01, 2.56091833e-01, 2.99604237e-01,\n","        1.78842932e-01],\n","       [2.85182685e-01, 3.78490597e-01, 1.34953201e-01, 1.03607357e-01,\n","        9.77662355e-02],\n","       [1.25561491e-01, 2.04373404e-01, 2.46103168e-01, 2.53801346e-01,\n","        1.70160636e-01],\n","       [1.33694947e-01, 1.88594043e-01, 2.33809575e-01, 2.59824574e-01,\n","        1.84076905e-01],\n","       [1.05567142e-01, 1.66478798e-01, 2.54240483e-01, 2.95930296e-01,\n","        1.77783281e-01],\n","       [2.84635961e-01, 3.77915174e-01, 1.35749444e-01, 1.03862263e-01,\n","        9.78371203e-02],\n","       [1.09372705e-01, 1.70507625e-01, 2.51314372e-01, 2.90445864e-01,\n","        1.78359464e-01],\n","       [2.00979531e-01, 3.14666748e-01, 1.74570307e-01, 1.72327161e-01,\n","        1.37456164e-01],\n","       [1.11577488e-01, 1.57638296e-01, 2.50729740e-01, 2.90430814e-01,\n","        1.89623654e-01],\n","       [1.23375729e-01, 1.97537765e-01, 2.39286944e-01, 2.71009326e-01,\n","        1.68790266e-01],\n","       [1.94747761e-01, 2.65390694e-01, 1.97704434e-01, 1.86011314e-01,\n","        1.56145856e-01],\n","       [1.10018715e-01, 1.56022251e-01, 2.51890004e-01, 2.92584419e-01,\n","        1.89484626e-01],\n","       [5.13935030e-01, 4.64369982e-01, 1.26810065e-02, 3.59937153e-03,\n","        5.41460980e-03],\n","       [3.23345602e-01, 4.22502756e-01, 1.07818484e-01, 7.32223094e-02,\n","        7.31109008e-02],\n","       [1.04432434e-01, 1.50159001e-01, 2.56061256e-01, 3.00467730e-01,\n","        1.88879639e-01],\n","       [1.17074884e-01, 1.63270116e-01, 2.46651500e-01, 2.82987505e-01,\n","        1.90015942e-01],\n","       [1.15753211e-01, 1.61925703e-01, 2.47630030e-01, 2.84755975e-01,\n","        1.89935103e-01],\n","       [1.95123941e-01, 2.79333234e-01, 1.99880898e-01, 1.80061743e-01,\n","        1.45600170e-01],\n","       [1.03504792e-01, 1.52889565e-01, 2.56671071e-01, 3.01309496e-01,\n","        1.85625061e-01],\n","       [9.94605646e-02, 1.44843593e-01, 2.59789586e-01, 3.07714641e-01,\n","        1.88191622e-01],\n","       [1.33243293e-01, 2.13998824e-01, 2.36362323e-01, 2.53649771e-01,\n","        1.62745759e-01],\n","       [3.71975690e-01, 4.64221597e-01, 7.62550905e-02, 4.18442413e-02,\n","        4.57033105e-02],\n","       [1.18201986e-01, 1.64411977e-01, 2.45818272e-01, 2.81489670e-01,\n","        1.90078139e-01],\n","       [3.99766773e-01, 4.49466527e-01, 6.88290000e-02, 3.81660052e-02,\n","        4.37717028e-02],\n","       [1.98609889e-01, 2.07091123e-01, 1.99477658e-01, 2.13350654e-01,\n","        1.81470647e-01],\n","       [2.09360212e-01, 3.01511437e-01, 1.90760165e-01, 1.63478002e-01,\n","        1.34890109e-01],\n","       [4.31105971e-01, 4.75134939e-01, 4.53893170e-02, 2.18014978e-02,\n","        2.65683401e-02]], dtype=float32)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["y_pred"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["array([1, 1, 1, 3, 3, 3, 1, 1, 3, 3, 3, 1, 3, 3, 1, 3, 1, 3, 3, 1, 3, 3,\n","       1, 1, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 3, 1, 3,\n","       3, 3, 1, 1, 3, 3, 1, 3, 3, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3,\n","       1, 1, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 1, 3, 1, 1, 3, 3, 3, 1, 3,\n","       3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 1, 1, 3, 3, 1, 3, 3, 2, 3, 3, 3,\n","       3, 0, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 1, 1, 1, 3, 1, 3, 1,\n","       1, 3, 1, 1, 3, 3, 3, 1, 0, 3, 1, 1, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3,\n","       3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 1, 3, 3, 1,\n","       3, 0, 1, 3, 3, 3, 1, 3, 3, 3, 1, 3, 1, 3, 1, 1], dtype=int64)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["y_pred_classes"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy Score: 0.3854166666666667\n"]}],"source":["accuracy = accuracy_score(y_test, y_pred_classes)\n","print(f'Accuracy Score: {accuracy}')"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      0.09      0.16        34\n","           1       0.47      0.70      0.56        40\n","           2       0.00      0.00      0.00        48\n","           3       0.34      0.98      0.50        44\n","           4       0.00      0.00      0.00        26\n","\n","    accuracy                           0.39       192\n","   macro avg       0.36      0.35      0.24       192\n","weighted avg       0.35      0.39      0.26       192\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Yash Thakar\\PROGRAMMING\\Quantum\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","c:\\Users\\Yash Thakar\\PROGRAMMING\\Quantum\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","c:\\Users\\Yash Thakar\\PROGRAMMING\\Quantum\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}],"source":["class_report = classification_report(y_test, y_pred_classes)\n","print('Classification Report:\\n', class_report)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m20/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"]}],"source":["y_pred = model.predict(x_train)\n","y_pred_classes = y_pred.argmax(axis=1)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy Score: 0.38219895287958117\n"]}],"source":["accuracy = accuracy_score(y_train, y_pred_classes)\n","print(f'Accuracy Score: {accuracy}')"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      0.17      0.29       140\n","           1       0.45      0.56      0.50       172\n","           2       1.00      0.01      0.02       162\n","           3       0.32      0.95      0.48       178\n","           4       0.00      0.00      0.00       112\n","\n","    accuracy                           0.38       764\n","   macro avg       0.56      0.34      0.26       764\n","weighted avg       0.57      0.38      0.28       764\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Yash Thakar\\PROGRAMMING\\Quantum\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","c:\\Users\\Yash Thakar\\PROGRAMMING\\Quantum\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","c:\\Users\\Yash Thakar\\PROGRAMMING\\Quantum\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}],"source":["class_report = classification_report(y_train, y_pred_classes)\n","print('Classification Report:\\n', class_report)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4572327,"sourceId":7812948,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":4}
