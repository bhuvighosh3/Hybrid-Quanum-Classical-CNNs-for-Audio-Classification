{"cells":[{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-11T06:39:18.643709Z","iopub.status.busy":"2024-03-11T06:39:18.643231Z","iopub.status.idle":"2024-03-11T06:39:37.117875Z","shell.execute_reply":"2024-03-11T06:39:37.116136Z","shell.execute_reply.started":"2024-03-11T06:39:18.643669Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","from sklearn.metrics import accuracy_score, classification_report\n","from keras.models import Sequential\n","from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n","from sklearn.model_selection import train_test_split\n","import numpy as np"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["df_x = pd.read_csv(\"urbansound8k_mfcc/13_reduced (1).csv\") "]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Feature_1</th>\n","      <th>Feature_2</th>\n","      <th>Feature_3</th>\n","      <th>Feature_4</th>\n","      <th>Feature_5</th>\n","      <th>Feature_6</th>\n","      <th>Feature_7</th>\n","      <th>Feature_8</th>\n","      <th>Feature_9</th>\n","      <th>Feature_10</th>\n","      <th>Feature_11</th>\n","      <th>Feature_12</th>\n","      <th>Feature_13</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-211.93698</td>\n","      <td>62.581220</td>\n","      <td>-122.813156</td>\n","      <td>-60.745296</td>\n","      <td>-13.893755</td>\n","      <td>-29.789837</td>\n","      <td>-3.978871</td>\n","      <td>11.682741</td>\n","      <td>12.963834</td>\n","      <td>8.336420</td>\n","      <td>-6.529818</td>\n","      <td>-2.996104</td>\n","      <td>-12.887945</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-417.00525</td>\n","      <td>99.336624</td>\n","      <td>-42.995586</td>\n","      <td>51.073326</td>\n","      <td>9.853778</td>\n","      <td>7.969693</td>\n","      <td>11.197088</td>\n","      <td>1.929118</td>\n","      <td>7.030397</td>\n","      <td>4.270228</td>\n","      <td>-3.584725</td>\n","      <td>13.890946</td>\n","      <td>-2.764493</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-452.39316</td>\n","      <td>112.362530</td>\n","      <td>-37.578075</td>\n","      <td>43.195866</td>\n","      <td>8.631845</td>\n","      <td>15.379369</td>\n","      <td>16.882149</td>\n","      <td>1.233047</td>\n","      <td>6.833121</td>\n","      <td>3.900115</td>\n","      <td>-5.168850</td>\n","      <td>8.300045</td>\n","      <td>1.904138</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-406.47922</td>\n","      <td>91.196610</td>\n","      <td>-25.043556</td>\n","      <td>42.784523</td>\n","      <td>11.586844</td>\n","      <td>5.054164</td>\n","      <td>12.431632</td>\n","      <td>-1.599949</td>\n","      <td>6.656064</td>\n","      <td>1.442354</td>\n","      <td>-4.624870</td>\n","      <td>14.211007</td>\n","      <td>0.434271</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-439.63873</td>\n","      <td>103.862240</td>\n","      <td>-42.658787</td>\n","      <td>50.690285</td>\n","      <td>12.209422</td>\n","      <td>15.873466</td>\n","      <td>11.729268</td>\n","      <td>1.533586</td>\n","      <td>11.292243</td>\n","      <td>2.548621</td>\n","      <td>-7.290973</td>\n","      <td>10.374461</td>\n","      <td>2.101837</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>8727</th>\n","      <td>-391.00000</td>\n","      <td>125.000000</td>\n","      <td>-40.600000</td>\n","      <td>25.900000</td>\n","      <td>1.730000</td>\n","      <td>5.580000</td>\n","      <td>16.900000</td>\n","      <td>7.890000</td>\n","      <td>3.490000</td>\n","      <td>-4.570000</td>\n","      <td>2.730000</td>\n","      <td>0.209000</td>\n","      <td>-4.850000</td>\n","    </tr>\n","    <tr>\n","      <th>8728</th>\n","      <td>-339.42715</td>\n","      <td>76.409100</td>\n","      <td>-35.309883</td>\n","      <td>41.984040</td>\n","      <td>-22.963875</td>\n","      <td>-13.623511</td>\n","      <td>27.856026</td>\n","      <td>-9.215821</td>\n","      <td>-5.666290</td>\n","      <td>13.024159</td>\n","      <td>-9.010244</td>\n","      <td>-1.397294</td>\n","      <td>-0.384217</td>\n","    </tr>\n","    <tr>\n","      <th>8729</th>\n","      <td>-297.00000</td>\n","      <td>102.000000</td>\n","      <td>-36.800000</td>\n","      <td>26.800000</td>\n","      <td>-0.249000</td>\n","      <td>3.960000</td>\n","      <td>11.100000</td>\n","      <td>1.910000</td>\n","      <td>0.677000</td>\n","      <td>-1.800000</td>\n","      <td>-1.640000</td>\n","      <td>-4.760000</td>\n","      <td>-9.210000</td>\n","    </tr>\n","    <tr>\n","      <th>8730</th>\n","      <td>-337.00000</td>\n","      <td>115.000000</td>\n","      <td>-44.800000</td>\n","      <td>25.000000</td>\n","      <td>-9.890000</td>\n","      <td>-2.150000</td>\n","      <td>22.700000</td>\n","      <td>0.234000</td>\n","      <td>-0.123000</td>\n","      <td>10.200000</td>\n","      <td>-2.780000</td>\n","      <td>-7.000000</td>\n","      <td>-0.481000</td>\n","    </tr>\n","    <tr>\n","      <th>8731</th>\n","      <td>-307.41763</td>\n","      <td>83.306740</td>\n","      <td>-25.756512</td>\n","      <td>35.448110</td>\n","      <td>4.414006</td>\n","      <td>-0.893325</td>\n","      <td>9.015661</td>\n","      <td>8.213615</td>\n","      <td>-1.967305</td>\n","      <td>-1.941081</td>\n","      <td>1.252807</td>\n","      <td>2.707129</td>\n","      <td>-7.433314</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8732 rows × 13 columns</p>\n","</div>"],"text/plain":["      Feature_1   Feature_2   Feature_3  Feature_4  Feature_5  Feature_6  \\\n","0    -211.93698   62.581220 -122.813156 -60.745296 -13.893755 -29.789837   \n","1    -417.00525   99.336624  -42.995586  51.073326   9.853778   7.969693   \n","2    -452.39316  112.362530  -37.578075  43.195866   8.631845  15.379369   \n","3    -406.47922   91.196610  -25.043556  42.784523  11.586844   5.054164   \n","4    -439.63873  103.862240  -42.658787  50.690285  12.209422  15.873466   \n","...         ...         ...         ...        ...        ...        ...   \n","8727 -391.00000  125.000000  -40.600000  25.900000   1.730000   5.580000   \n","8728 -339.42715   76.409100  -35.309883  41.984040 -22.963875 -13.623511   \n","8729 -297.00000  102.000000  -36.800000  26.800000  -0.249000   3.960000   \n","8730 -337.00000  115.000000  -44.800000  25.000000  -9.890000  -2.150000   \n","8731 -307.41763   83.306740  -25.756512  35.448110   4.414006  -0.893325   \n","\n","      Feature_7  Feature_8  Feature_9  Feature_10  Feature_11  Feature_12  \\\n","0     -3.978871  11.682741  12.963834    8.336420   -6.529818   -2.996104   \n","1     11.197088   1.929118   7.030397    4.270228   -3.584725   13.890946   \n","2     16.882149   1.233047   6.833121    3.900115   -5.168850    8.300045   \n","3     12.431632  -1.599949   6.656064    1.442354   -4.624870   14.211007   \n","4     11.729268   1.533586  11.292243    2.548621   -7.290973   10.374461   \n","...         ...        ...        ...         ...         ...         ...   \n","8727  16.900000   7.890000   3.490000   -4.570000    2.730000    0.209000   \n","8728  27.856026  -9.215821  -5.666290   13.024159   -9.010244   -1.397294   \n","8729  11.100000   1.910000   0.677000   -1.800000   -1.640000   -4.760000   \n","8730  22.700000   0.234000  -0.123000   10.200000   -2.780000   -7.000000   \n","8731   9.015661   8.213615  -1.967305   -1.941081    1.252807    2.707129   \n","\n","      Feature_13  \n","0     -12.887945  \n","1      -2.764493  \n","2       1.904138  \n","3       0.434271  \n","4       2.101837  \n","...          ...  \n","8727   -4.850000  \n","8728   -0.384217  \n","8729   -9.210000  \n","8730   -0.481000  \n","8731   -7.433314  \n","\n","[8732 rows x 13 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df_x"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["df_y = pd.read_csv(\"urbansound8k_mfcc/mfcc52_y.csv\")"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["x = np.array(df_x).reshape(-1, 13, 1)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Yash Thakar\\PROGRAMMING\\Quantum\\env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]}],"source":["label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(df_y)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[   0    1    2    3    4    5    6    7    8    9]\n"," [1000  429 1000 1000 1000 1000  374 1000  929 1000]]\n"]}],"source":["unique_elements, counts_elements = np.unique(y_encoded, return_counts=True)\n","print(np.asarray((unique_elements, counts_elements)))"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, \n","                                                    test_size=0.2, random_state = 42)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.1274 - loss: 4.7920 - val_accuracy: 0.2564 - val_loss: 2.0482\n","Epoch 2/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.2197 - loss: 2.1431 - val_accuracy: 0.3669 - val_loss: 1.9266\n","Epoch 3/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2656 - loss: 2.0233 - val_accuracy: 0.4110 - val_loss: 1.8349\n","Epoch 4/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3078 - loss: 1.9466 - val_accuracy: 0.4402 - val_loss: 1.6962\n","Epoch 5/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3534 - loss: 1.8751 - val_accuracy: 0.4310 - val_loss: 1.6777\n","Epoch 6/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3697 - loss: 1.8045 - val_accuracy: 0.4665 - val_loss: 1.5938\n","Epoch 7/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3898 - loss: 1.7577 - val_accuracy: 0.4596 - val_loss: 1.5623\n","Epoch 8/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4036 - loss: 1.7127 - val_accuracy: 0.4831 - val_loss: 1.5258\n","Epoch 9/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4261 - loss: 1.6613 - val_accuracy: 0.5043 - val_loss: 1.5126\n","Epoch 10/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4152 - loss: 1.6843 - val_accuracy: 0.5180 - val_loss: 1.4730\n","Epoch 11/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4490 - loss: 1.5713 - val_accuracy: 0.5295 - val_loss: 1.4340\n","Epoch 12/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4637 - loss: 1.5719 - val_accuracy: 0.5266 - val_loss: 1.4202\n","Epoch 13/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4843 - loss: 1.5176 - val_accuracy: 0.5341 - val_loss: 1.4116\n","Epoch 14/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4571 - loss: 1.5479 - val_accuracy: 0.5592 - val_loss: 1.3466\n","Epoch 15/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4887 - loss: 1.4915 - val_accuracy: 0.5472 - val_loss: 1.3440\n","Epoch 16/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4828 - loss: 1.5146 - val_accuracy: 0.5501 - val_loss: 1.3279\n","Epoch 17/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4893 - loss: 1.4837 - val_accuracy: 0.5793 - val_loss: 1.2741\n","Epoch 18/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5117 - loss: 1.4429 - val_accuracy: 0.5810 - val_loss: 1.2866\n","Epoch 19/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5243 - loss: 1.4259 - val_accuracy: 0.5902 - val_loss: 1.2348\n","Epoch 20/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5228 - loss: 1.4018 - val_accuracy: 0.6056 - val_loss: 1.2409\n","Epoch 21/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5210 - loss: 1.4033 - val_accuracy: 0.5987 - val_loss: 1.2114\n","Epoch 22/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5273 - loss: 1.3634 - val_accuracy: 0.5936 - val_loss: 1.2023\n","Epoch 23/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 1.3555 - val_accuracy: 0.6010 - val_loss: 1.2094\n","Epoch 24/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5464 - loss: 1.3347 - val_accuracy: 0.6193 - val_loss: 1.1782\n","Epoch 25/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5434 - loss: 1.3236 - val_accuracy: 0.6056 - val_loss: 1.1951\n","Epoch 26/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5482 - loss: 1.3158 - val_accuracy: 0.6251 - val_loss: 1.1460\n","Epoch 27/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5596 - loss: 1.2980 - val_accuracy: 0.6279 - val_loss: 1.1291\n","Epoch 28/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5661 - loss: 1.2937 - val_accuracy: 0.6337 - val_loss: 1.1337\n","Epoch 29/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5567 - loss: 1.3010 - val_accuracy: 0.6331 - val_loss: 1.1164\n","Epoch 30/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5707 - loss: 1.2756 - val_accuracy: 0.6377 - val_loss: 1.1064\n","Epoch 31/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5596 - loss: 1.2635 - val_accuracy: 0.6411 - val_loss: 1.0899\n","Epoch 32/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5744 - loss: 1.2567 - val_accuracy: 0.6256 - val_loss: 1.1076\n","Epoch 33/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5658 - loss: 1.2598 - val_accuracy: 0.6463 - val_loss: 1.0782\n","Epoch 34/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5687 - loss: 1.2346 - val_accuracy: 0.6463 - val_loss: 1.0615\n","Epoch 35/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5818 - loss: 1.2230 - val_accuracy: 0.6388 - val_loss: 1.1219\n","Epoch 36/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5821 - loss: 1.2356 - val_accuracy: 0.6548 - val_loss: 1.0481\n","Epoch 37/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5933 - loss: 1.2080 - val_accuracy: 0.6503 - val_loss: 1.0509\n","Epoch 38/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5798 - loss: 1.2452 - val_accuracy: 0.6577 - val_loss: 1.0415\n","Epoch 39/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5958 - loss: 1.2012 - val_accuracy: 0.6629 - val_loss: 1.0431\n","Epoch 40/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5986 - loss: 1.1835 - val_accuracy: 0.6611 - val_loss: 1.0467\n","Epoch 41/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6138 - loss: 1.1578 - val_accuracy: 0.6583 - val_loss: 1.0347\n","Epoch 42/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6039 - loss: 1.1506 - val_accuracy: 0.6772 - val_loss: 1.0063\n","Epoch 43/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5992 - loss: 1.1829 - val_accuracy: 0.6646 - val_loss: 1.0105\n","Epoch 44/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6191 - loss: 1.1718 - val_accuracy: 0.6709 - val_loss: 1.0211\n","Epoch 45/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5964 - loss: 1.1717 - val_accuracy: 0.6737 - val_loss: 1.0071\n","Epoch 46/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6154 - loss: 1.1565 - val_accuracy: 0.6669 - val_loss: 1.0101\n","Epoch 47/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6177 - loss: 1.1523 - val_accuracy: 0.6823 - val_loss: 1.0025\n","Epoch 48/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6190 - loss: 1.1286 - val_accuracy: 0.6691 - val_loss: 1.0053\n","Epoch 49/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6263 - loss: 1.1181 - val_accuracy: 0.6823 - val_loss: 0.9920\n","Epoch 50/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6270 - loss: 1.1292 - val_accuracy: 0.6869 - val_loss: 0.9621\n","Epoch 51/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6203 - loss: 1.1296 - val_accuracy: 0.6955 - val_loss: 0.9738\n","Epoch 52/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6220 - loss: 1.1240 - val_accuracy: 0.6898 - val_loss: 0.9761\n","Epoch 53/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6287 - loss: 1.1189 - val_accuracy: 0.6789 - val_loss: 0.9795\n","Epoch 54/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6261 - loss: 1.0984 - val_accuracy: 0.6932 - val_loss: 0.9716\n","Epoch 55/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6327 - loss: 1.0918 - val_accuracy: 0.6869 - val_loss: 0.9902\n","Epoch 56/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6268 - loss: 1.1028 - val_accuracy: 0.6949 - val_loss: 0.9717\n","Epoch 57/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6291 - loss: 1.1216 - val_accuracy: 0.6875 - val_loss: 0.9611\n","Epoch 58/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6404 - loss: 1.0767 - val_accuracy: 0.6995 - val_loss: 0.9532\n","Epoch 59/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6301 - loss: 1.0990 - val_accuracy: 0.6800 - val_loss: 0.9507\n","Epoch 60/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6237 - loss: 1.1103 - val_accuracy: 0.6983 - val_loss: 0.9446\n","Epoch 61/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6363 - loss: 1.0599 - val_accuracy: 0.6943 - val_loss: 0.9374\n","Epoch 62/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6417 - loss: 1.0614 - val_accuracy: 0.6978 - val_loss: 0.9323\n","Epoch 63/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6419 - loss: 1.0632 - val_accuracy: 0.7018 - val_loss: 0.9296\n","Epoch 64/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6465 - loss: 1.0351 - val_accuracy: 0.7046 - val_loss: 0.9219\n","Epoch 65/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6374 - loss: 1.0667 - val_accuracy: 0.7012 - val_loss: 0.9275\n","Epoch 66/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6522 - loss: 1.0308 - val_accuracy: 0.6898 - val_loss: 0.9301\n","Epoch 67/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6478 - loss: 1.0486 - val_accuracy: 0.7012 - val_loss: 0.9164\n","Epoch 68/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6360 - loss: 1.0358 - val_accuracy: 0.7064 - val_loss: 0.9306\n","Epoch 69/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6595 - loss: 1.0303 - val_accuracy: 0.7121 - val_loss: 0.9233\n","Epoch 70/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6595 - loss: 1.0008 - val_accuracy: 0.7109 - val_loss: 0.9190\n","Epoch 71/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6619 - loss: 1.0197 - val_accuracy: 0.7121 - val_loss: 0.8960\n","Epoch 72/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6477 - loss: 1.0444 - val_accuracy: 0.7058 - val_loss: 0.9196\n","Epoch 73/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6657 - loss: 1.0026 - val_accuracy: 0.7127 - val_loss: 0.9006\n","Epoch 74/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6454 - loss: 1.0415 - val_accuracy: 0.7001 - val_loss: 0.9194\n","Epoch 75/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6595 - loss: 1.0374 - val_accuracy: 0.7092 - val_loss: 0.9039\n","Epoch 76/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6698 - loss: 0.9808 - val_accuracy: 0.7224 - val_loss: 0.8985\n","Epoch 77/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6657 - loss: 0.9990 - val_accuracy: 0.7172 - val_loss: 0.9055\n","Epoch 78/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6670 - loss: 0.9873 - val_accuracy: 0.7075 - val_loss: 0.9077\n","Epoch 79/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6532 - loss: 1.0168 - val_accuracy: 0.7161 - val_loss: 0.9045\n","Epoch 80/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6634 - loss: 1.0043 - val_accuracy: 0.7172 - val_loss: 0.9007\n","Epoch 81/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6661 - loss: 0.9938 - val_accuracy: 0.7218 - val_loss: 0.8854\n","Epoch 82/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6657 - loss: 0.9813 - val_accuracy: 0.7252 - val_loss: 0.8705\n","Epoch 83/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6672 - loss: 0.9759 - val_accuracy: 0.7167 - val_loss: 0.8797\n","Epoch 84/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6607 - loss: 0.9945 - val_accuracy: 0.7155 - val_loss: 0.8995\n","Epoch 85/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6738 - loss: 0.9841 - val_accuracy: 0.7172 - val_loss: 0.8800\n","Epoch 86/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6713 - loss: 0.9678 - val_accuracy: 0.7304 - val_loss: 0.8646\n","Epoch 87/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6692 - loss: 0.9694 - val_accuracy: 0.7258 - val_loss: 0.8856\n","Epoch 88/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6641 - loss: 0.9902 - val_accuracy: 0.7333 - val_loss: 0.8733\n","Epoch 89/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6767 - loss: 0.9660 - val_accuracy: 0.7258 - val_loss: 0.8610\n","Epoch 90/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6798 - loss: 0.9510 - val_accuracy: 0.7281 - val_loss: 0.8693\n","Epoch 91/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6729 - loss: 0.9687 - val_accuracy: 0.7321 - val_loss: 0.8662\n","Epoch 92/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6789 - loss: 0.9571 - val_accuracy: 0.7264 - val_loss: 0.8813\n","Epoch 93/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6847 - loss: 0.9528 - val_accuracy: 0.7264 - val_loss: 0.8670\n","Epoch 94/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6746 - loss: 0.9545 - val_accuracy: 0.7378 - val_loss: 0.8494\n","Epoch 95/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6886 - loss: 0.9316 - val_accuracy: 0.7367 - val_loss: 0.8554\n","Epoch 96/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6887 - loss: 0.9217 - val_accuracy: 0.7390 - val_loss: 0.8332\n","Epoch 97/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6845 - loss: 0.9228 - val_accuracy: 0.7378 - val_loss: 0.8562\n","Epoch 98/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6906 - loss: 0.9185 - val_accuracy: 0.7298 - val_loss: 0.8580\n","Epoch 99/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6859 - loss: 0.9144 - val_accuracy: 0.7258 - val_loss: 0.8707\n","Epoch 100/100\n","\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6736 - loss: 0.9496 - val_accuracy: 0.7390 - val_loss: 0.8607\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x227652ff250>"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Create the model\n","model = Sequential()\n","\n","# Add convolutional layers\n","model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(13, 1)))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Conv1D(64, kernel_size=3, activation='relu'))\n","model.add(MaxPooling1D(pool_size=2))\n","\n","# Flatten the output of the convolutional layers\n","model.add(Flatten())\n","\n","# Add dense layers\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.3))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dropout(0.3))\n","model.add(Dense(10, activation='softmax')) \n","\n","\n","# Compile the model\n","optimiser = tf.keras.optimizers.Adam(learning_rate = 0.0002)\n","cb = [EarlyStopping(patience=10,monitor='accuracy',mode='max',restore_best_weights=True)]\n","model.compile(optimizer=optimiser, loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n","\n","# Train the model\n","model.fit(x_train, y_train, epochs=100, batch_size=16, validation_data=(x_test, y_test), callbacks = cb)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"]}],"source":["y_pred = model.predict(x_test)\n","y_pred_classes = y_pred.argmax(axis=1)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["array([[7.53685758e-02, 2.05620036e-01, 1.40449004e-02, ...,\n","        8.72160196e-02, 3.64010513e-01, 4.73930985e-02],\n","       [3.23050481e-04, 4.08787699e-03, 1.10648535e-02, ...,\n","        1.17669064e-04, 8.44187569e-04, 6.64489865e-01],\n","       [4.41824390e-08, 4.35985578e-03, 2.86255636e-05, ...,\n","        1.00772058e-06, 8.23178489e-05, 2.85614951e-04],\n","       ...,\n","       [3.32564935e-02, 4.99169668e-03, 5.79742268e-02, ...,\n","        3.73778306e-03, 4.61186777e-04, 1.41807556e-01],\n","       [1.10436250e-02, 4.39084461e-03, 3.23341340e-02, ...,\n","        3.68286943e-04, 1.48098113e-03, 3.21804315e-01],\n","       [1.25901076e-08, 8.50500888e-04, 1.47116316e-05, ...,\n","        5.73727038e-11, 9.76267755e-01, 4.63794335e-04]], dtype=float32)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["y_pred"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["array([8, 9, 4, ..., 5, 3, 8], dtype=int64)"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["y_pred_classes"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy Score: 0.7298225529479107\n"]}],"source":["accuracy = accuracy_score(y_test, y_pred_classes)\n","print(f'Accuracy Score: {accuracy}')"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.72      0.78      0.75       203\n","           1       0.92      0.56      0.70        86\n","           2       0.50      0.66      0.57       183\n","           3       0.74      0.71      0.72       201\n","           4       0.77      0.67      0.72       206\n","           5       0.84      0.89      0.86       193\n","           6       0.79      0.51      0.62        72\n","           7       0.84      0.87      0.85       208\n","           8       0.78      0.85      0.81       165\n","           9       0.64      0.60      0.62       230\n","\n","    accuracy                           0.73      1747\n","   macro avg       0.75      0.71      0.72      1747\n","weighted avg       0.74      0.73      0.73      1747\n","\n"]}],"source":["class_report = classification_report(y_test, y_pred_classes)\n","print('Classification Report:\\n', class_report)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"]}],"source":["y_pred = model.predict(x_train)\n","y_pred_classes = y_pred.argmax(axis=1)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy Score: 0.7670722977809592\n"]}],"source":["accuracy = accuracy_score(y_train, y_pred_classes)\n","print(f'Accuracy Score: {accuracy}')"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.82      0.81      0.82       797\n","           1       0.85      0.56      0.67       343\n","           2       0.58      0.71      0.64       817\n","           3       0.75      0.69      0.72       799\n","           4       0.89      0.75      0.81       794\n","           5       0.81      0.90      0.85       807\n","           6       0.84      0.49      0.62       302\n","           7       0.88      0.91      0.89       792\n","           8       0.84      0.88      0.86       764\n","           9       0.60      0.68      0.64       770\n","\n","    accuracy                           0.77      6985\n","   macro avg       0.79      0.74      0.75      6985\n","weighted avg       0.78      0.77      0.77      6985\n","\n"]}],"source":["class_report = classification_report(y_train, y_pred_classes)\n","print('Classification Report:\\n', class_report)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4572327,"sourceId":7811597,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":4}
